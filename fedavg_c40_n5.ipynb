{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xSmMvB99RYsx","executionInfo":{"status":"ok","timestamp":1713173359510,"user_tz":-120,"elapsed":19084,"user":{"displayName":"ff ff","userId":"03856258937076952853"}},"outputId":"4f6b3548-9d2b-4179-bcac-d0b31506a7a8"},"id":"xSmMvB99RYsx","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import os\n","os.chdir('/content/drive/MyDrive/')"],"metadata":{"id":"TbQzihueRgMg"},"id":"TbQzihueRgMg","execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install kneed"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tNnLJQ2p6K-1","executionInfo":{"status":"ok","timestamp":1713173365008,"user_tz":-120,"elapsed":5499,"user":{"displayName":"ff ff","userId":"03856258937076952853"}},"outputId":"0104aff2-40fe-4638-8244-b08ef440b0ca"},"id":"tNnLJQ2p6K-1","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting kneed\n","  Downloading kneed-0.8.5-py3-none-any.whl (10 kB)\n","Requirement already satisfied: numpy>=1.14.2 in /usr/local/lib/python3.10/dist-packages (from kneed) (1.25.2)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from kneed) (1.11.4)\n","Installing collected packages: kneed\n","Successfully installed kneed-0.8.5\n"]}]},{"cell_type":"code","execution_count":null,"id":"34805abf-0117-4183-a5c5-d3e62d880b1f","metadata":{"execution":{"iopub.execute_input":"2023-09-12T10:19:29.517057Z","iopub.status.busy":"2023-09-12T10:19:29.517057Z","iopub.status.idle":"2023-09-12T10:19:34.312066Z","shell.execute_reply":"2023-09-12T10:19:34.311067Z","shell.execute_reply.started":"2023-09-12T10:19:29.517057Z"},"id":"34805abf-0117-4183-a5c5-d3e62d880b1f","tags":[]},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import copy\n","\n","import torch\n","from torch.utils.data import TensorDataset, DataLoader\n","from sklearn.preprocessing import MinMaxScaler\n","\n","from data import fetch_dataset\n","from util import move_sliding_window, num_params\n","from model import LSTMNet, GRUNet\n","from algorithm import fedavg\n","\n","pd.set_option('display.max_columns', None)\n","pd.set_option('display.max_columns', None)\n","np.set_printoptions(suppress=True, floatmode='fixed')"]},{"cell_type":"code","execution_count":null,"id":"5d3d5845-ec85-4781-9936-c22e6cd99836","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-09-12T10:19:34.314067Z","iopub.status.busy":"2023-09-12T10:19:34.314067Z","iopub.status.idle":"2023-09-12T10:19:34.328071Z","shell.execute_reply":"2023-09-12T10:19:34.327070Z","shell.execute_reply.started":"2023-09-12T10:19:34.314067Z"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1713173373272,"user":{"displayName":"ff ff","userId":"03856258937076952853"},"user_tz":-120},"id":"5d3d5845-ec85-4781-9936-c22e6cd99836","outputId":"f57c91bb-de52-4704-9e3a-e98c0d4c1c83","tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":["running on gpu\n"]}],"source":["if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","    print('running on gpu')\n","else:\n","    device = torch.device(\"cpu\")"]},{"cell_type":"markdown","id":"4c84b7fb-5aa5-42f3-913c-bab77727e9b7","metadata":{"id":"4c84b7fb-5aa5-42f3-913c-bab77727e9b7"},"source":["# Parameters"]},{"cell_type":"code","execution_count":null,"id":"51a5da4f-168c-4094-928e-de826f846780","metadata":{"execution":{"iopub.execute_input":"2023-09-12T10:19:34.329070Z","iopub.status.busy":"2023-09-12T10:19:34.329070Z","iopub.status.idle":"2023-09-12T10:19:34.344073Z","shell.execute_reply":"2023-09-12T10:19:34.343074Z","shell.execute_reply.started":"2023-09-12T10:19:34.329070Z"},"id":"51a5da4f-168c-4094-928e-de826f846780","tags":[]},"outputs":[],"source":["window_size = 90 # Define window_size period and split inputs/labels\\\n","batch_size = 1024\n","label_col_index = 0\n","\n","# seq_len = 90  # (timestamps)\n","hidden_dim = 256\n","n_layers = 2\n","lr = 0.001\n","output_dim = 1\n","\n","#fed train params\n","num_local_epochs = 1\n","max_rounds = 100 #nb of total rounds for training\n","num_clients_per_round = 40 #number of clients to participate in training"]},{"cell_type":"markdown","id":"052833d6-a7f4-4b5f-b387-17f5e0f8cd1f","metadata":{"id":"052833d6-a7f4-4b5f-b387-17f5e0f8cd1f"},"source":["# Data Preperation"]},{"cell_type":"code","execution_count":null,"id":"f4c669f6-7198-4ae1-8553-f2d7894f7a7c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-09-12T10:19:34.346074Z","iopub.status.busy":"2023-09-12T10:19:34.345076Z","iopub.status.idle":"2023-09-12T10:19:52.069385Z","shell.execute_reply":"2023-09-12T10:19:52.067384Z","shell.execute_reply.started":"2023-09-12T10:19:34.346074Z"},"id":"f4c669f6-7198-4ae1-8553-f2d7894f7a7c","outputId":"815866bf-e3f9-4cb1-f5e7-38663089bf50","tags":[],"executionInfo":{"status":"ok","timestamp":1713173592248,"user_tz":-120,"elapsed":218987,"user":{"displayName":"ff ff","userId":"03856258937076952853"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Floor0_p4\n","Floor1_p8\n","Floor2_p9\n","Floor3_p8\n","Floor4_p2\n","Floor5_p2\n","Floor6_p6\n","Floor7_p6\n","Floor8_p6\n","Floor9_p7\n","Floor10_p7\n","Floor11_p3\n","Floor12_p6\n","Floor13_p4\n","Floor14_p7\n","Floor15_p10\n","Floor16_p4\n","Floor17_p10\n","Floor18_p7\n","Floor19_p8\n","Floor20_p7\n","Floor21_p2\n","Floor22_p7\n","Floor23_p11\n","Floor24_p11\n","Floor25_p3\n","Floor26_p6\n","Floor27_p2\n","Floor28_p4\n","Floor29_p3\n","Floor30_p10\n","Floor31_p3\n","Floor32_p8\n","Floor33_p4\n","Floor34_p10\n","Floor35_p2\n","Floor36_p11\n","Floor37_p7\n","Floor38_p5\n","Floor39_p11\n"]}],"source":["dataframes = fetch_dataset(\"./cleanedd\")"]},{"cell_type":"code","execution_count":null,"id":"1cdbefe5-d379-4b86-aa22-6aaa8b882c4e","metadata":{"execution":{"iopub.execute_input":"2023-09-12T10:19:52.072385Z","iopub.status.busy":"2023-09-12T10:19:52.071385Z","iopub.status.idle":"2023-09-12T10:19:52.083388Z","shell.execute_reply":"2023-09-12T10:19:52.082388Z","shell.execute_reply.started":"2023-09-12T10:19:52.072385Z"},"id":"1cdbefe5-d379-4b86-aa22-6aaa8b882c4e","tags":[]},"outputs":[],"source":["n_clients = len(dataframes) #total number of clients to partition data into"]},{"cell_type":"code","execution_count":null,"id":"0d773663-a9bc-47c2-b9f7-1c9349f533fb","metadata":{"execution":{"iopub.execute_input":"2023-09-12T10:19:52.085390Z","iopub.status.busy":"2023-09-12T10:19:52.084388Z","iopub.status.idle":"2023-09-12T10:19:52.103393Z","shell.execute_reply":"2023-09-12T10:19:52.102392Z","shell.execute_reply.started":"2023-09-12T10:19:52.085390Z"},"id":"0d773663-a9bc-47c2-b9f7-1c9349f533fb","tags":[],"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713173592248,"user_tz":-120,"elapsed":3,"user":{"displayName":"ff ff","userId":"03856258937076952853"}},"outputId":"2e60d6f2-0bc8-4370-ccc3-cb242fcbfe95"},"outputs":[{"output_type":"stream","name":"stdout","text":["Index(['total_demand', 'z1_AC1(kW)', 'z1_AC2(kW)', 'z1_AC3(kW)', 'z1_AC4(kW)',\n","       'z1_Light(kW)', 'z1_Plug(kW)', 'z2_AC1(kW)', 'z2_Light(kW)',\n","       'z2_Plug(kW)', 'z3_Light(kW)', 'z3_Plug(kW)', 'z4_AC1(kW)',\n","       'z4_Light(kW)', 'z4_Plug(kW)', 'z5_AC1(kW)', 'z5_Light(kW)',\n","       'z5_Plug(kW)', 'Year', 'Month', 'Day', 'Hour', 'Minute'],\n","      dtype='object')\n","(72864, 23)\n","Index(['total_demand', 'z1_AC1(kW)', 'z1_AC2(kW)', 'z1_AC3(kW)', 'z1_AC4(kW)',\n","       'z1_Light(kW)', 'z1_Plug(kW)', 'z2_AC1(kW)', 'z2_Light(kW)',\n","       'z2_Plug(kW)', 'z3_Light(kW)', 'z3_Plug(kW)', 'z4_AC1(kW)',\n","       'z4_Light(kW)', 'z4_Plug(kW)', 'z5_AC1(kW)', 'z5_Light(kW)',\n","       'z5_Plug(kW)', 'Year', 'Month', 'Day', 'Hour', 'Minute'],\n","      dtype='object')\n","(72864, 23)\n","Index(['total_demand', 'z1_AC1(kW)', 'z1_AC2(kW)', 'z1_AC3(kW)', 'z1_AC4(kW)',\n","       'z1_Light(kW)', 'z1_Plug(kW)', 'z2_AC1(kW)', 'z2_Light(kW)',\n","       'z2_Plug(kW)', 'z3_Light(kW)', 'z3_Plug(kW)', 'z4_AC1(kW)',\n","       'z4_Light(kW)', 'z4_Plug(kW)', 'z5_AC1(kW)', 'z5_Light(kW)',\n","       'z5_Plug(kW)', 'Year', 'Month', 'Day', 'Hour', 'Minute'],\n","      dtype='object')\n","(72864, 23)\n","Index(['total_demand', 'z1_AC1(kW)', 'z1_AC2(kW)', 'z1_AC3(kW)', 'z1_AC4(kW)',\n","       'z1_Light(kW)', 'z1_Plug(kW)', 'z2_AC1(kW)', 'z2_Light(kW)',\n","       'z2_Plug(kW)', 'z3_Light(kW)', 'z3_Plug(kW)', 'z4_AC1(kW)',\n","       'z4_Light(kW)', 'z4_Plug(kW)', 'z5_AC1(kW)', 'z5_Light(kW)',\n","       'z5_Plug(kW)', 'Year', 'Month', 'Day', 'Hour', 'Minute'],\n","      dtype='object')\n","(72864, 23)\n","Index(['total_demand', 'z1_AC1(kW)', 'z1_AC2(kW)', 'z1_AC3(kW)', 'z1_AC4(kW)',\n","       'z1_Light(kW)', 'z1_Plug(kW)', 'z2_AC1(kW)', 'z2_Light(kW)',\n","       'z2_Plug(kW)', 'z3_Light(kW)', 'z3_Plug(kW)', 'z4_AC1(kW)',\n","       'z4_Light(kW)', 'z4_Plug(kW)', 'z5_AC1(kW)', 'z5_Light(kW)',\n","       'z5_Plug(kW)', 'Year', 'Month', 'Day', 'Hour', 'Minute'],\n","      dtype='object')\n","(72864, 23)\n","Index(['total_demand', 'z1_AC1(kW)', 'z1_AC2(kW)', 'z1_AC3(kW)', 'z1_AC4(kW)',\n","       'z1_Light(kW)', 'z1_Plug(kW)', 'z2_AC1(kW)', 'z2_Light(kW)',\n","       'z2_Plug(kW)', 'z3_Light(kW)', 'z3_Plug(kW)', 'z4_AC1(kW)',\n","       'z4_Light(kW)', 'z4_Plug(kW)', 'z5_AC1(kW)', 'z5_Light(kW)',\n","       'z5_Plug(kW)', 'Year', 'Month', 'Day', 'Hour', 'Minute'],\n","      dtype='object')\n","(72864, 23)\n","Index(['total_demand', 'z1_AC1(kW)', 'z1_AC2(kW)', 'z1_AC3(kW)', 'z1_AC4(kW)',\n","       'z1_Light(kW)', 'z1_Plug(kW)', 'z2_AC1(kW)', 'z2_Light(kW)',\n","       'z2_Plug(kW)', 'z3_Light(kW)', 'z3_Plug(kW)', 'z4_AC1(kW)',\n","       'z4_Light(kW)', 'z4_Plug(kW)', 'z5_AC1(kW)', 'z5_Light(kW)',\n","       'z5_Plug(kW)', 'Year', 'Month', 'Day', 'Hour', 'Minute'],\n","      dtype='object')\n","(72864, 23)\n","Index(['total_demand', 'z1_AC1(kW)', 'z1_AC2(kW)', 'z1_AC3(kW)', 'z1_AC4(kW)',\n","       'z1_Light(kW)', 'z1_Plug(kW)', 'z2_AC1(kW)', 'z2_Light(kW)',\n","       'z2_Plug(kW)', 'z3_Light(kW)', 'z3_Plug(kW)', 'z4_AC1(kW)',\n","       'z4_Light(kW)', 'z4_Plug(kW)', 'z5_AC1(kW)', 'z5_Light(kW)',\n","       'z5_Plug(kW)', 'Year', 'Month', 'Day', 'Hour', 'Minute'],\n","      dtype='object')\n","(72864, 23)\n","Index(['total_demand', 'z1_AC1(kW)', 'z1_AC2(kW)', 'z1_AC3(kW)', 'z1_AC4(kW)',\n","       'z1_Light(kW)', 'z1_Plug(kW)', 'z2_AC1(kW)', 'z2_Light(kW)',\n","       'z2_Plug(kW)', 'z3_Light(kW)', 'z3_Plug(kW)', 'z4_AC1(kW)',\n","       'z4_Light(kW)', 'z4_Plug(kW)', 'z5_AC1(kW)', 'z5_Light(kW)',\n","       'z5_Plug(kW)', 'Year', 'Month', 'Day', 'Hour', 'Minute'],\n","      dtype='object')\n","(72864, 23)\n","Index(['total_demand', 'z1_AC1(kW)', 'z1_AC2(kW)', 'z1_AC3(kW)', 'z1_AC4(kW)',\n","       'z1_Light(kW)', 'z1_Plug(kW)', 'z2_AC1(kW)', 'z2_Light(kW)',\n","       'z2_Plug(kW)', 'z3_Light(kW)', 'z3_Plug(kW)', 'z4_AC1(kW)',\n","       'z4_Light(kW)', 'z4_Plug(kW)', 'z5_AC1(kW)', 'z5_Light(kW)',\n","       'z5_Plug(kW)', 'Year', 'Month', 'Day', 'Hour', 'Minute'],\n","      dtype='object')\n","(72864, 23)\n","Index(['total_demand', 'z1_AC1(kW)', 'z1_AC2(kW)', 'z1_AC3(kW)', 'z1_AC4(kW)',\n","       'z1_Light(kW)', 'z1_Plug(kW)', 'z2_AC1(kW)', 'z2_Light(kW)',\n","       'z2_Plug(kW)', 'z3_Light(kW)', 'z3_Plug(kW)', 'z4_AC1(kW)',\n","       'z4_Light(kW)', 'z4_Plug(kW)', 'z5_AC1(kW)', 'z5_Light(kW)',\n","       'z5_Plug(kW)', 'Year', 'Month', 'Day', 'Hour', 'Minute'],\n","      dtype='object')\n","(70899, 23)\n","Index(['total_demand', 'z1_AC1(kW)', 'z1_AC2(kW)', 'z1_AC3(kW)', 'z1_AC4(kW)',\n","       'z1_Light(kW)', 'z1_Plug(kW)', 'z2_AC1(kW)', 'z2_Light(kW)',\n","       'z2_Plug(kW)', 'z3_Light(kW)', 'z3_Plug(kW)', 'z4_AC1(kW)',\n","       'z4_Light(kW)', 'z4_Plug(kW)', 'z5_AC1(kW)', 'z5_Light(kW)',\n","       'z5_Plug(kW)', 'Year', 'Month', 'Day', 'Hour', 'Minute'],\n","      dtype='object')\n","(72864, 23)\n","Index(['total_demand', 'z1_AC1(kW)', 'z1_AC2(kW)', 'z1_AC3(kW)', 'z1_AC4(kW)',\n","       'z1_Light(kW)', 'z1_Plug(kW)', 'z2_AC1(kW)', 'z2_Light(kW)',\n","       'z2_Plug(kW)', 'z3_Light(kW)', 'z3_Plug(kW)', 'z4_AC1(kW)',\n","       'z4_Light(kW)', 'z4_Plug(kW)', 'z5_AC1(kW)', 'z5_Light(kW)',\n","       'z5_Plug(kW)', 'Year', 'Month', 'Day', 'Hour', 'Minute'],\n","      dtype='object')\n","(72838, 23)\n","Index(['total_demand', 'z1_AC1(kW)', 'z1_AC2(kW)', 'z1_AC3(kW)', 'z1_AC4(kW)',\n","       'z1_Light(kW)', 'z1_Plug(kW)', 'z2_AC1(kW)', 'z2_Light(kW)',\n","       'z2_Plug(kW)', 'z3_Light(kW)', 'z3_Plug(kW)', 'z4_AC1(kW)',\n","       'z4_Light(kW)', 'z4_Plug(kW)', 'z5_AC1(kW)', 'z5_Light(kW)',\n","       'z5_Plug(kW)', 'Year', 'Month', 'Day', 'Hour', 'Minute'],\n","      dtype='object')\n","(72861, 23)\n","Index(['total_demand', 'z1_AC1(kW)', 'z1_AC2(kW)', 'z1_AC3(kW)', 'z1_AC4(kW)',\n","       'z1_Light(kW)', 'z1_Plug(kW)', 'z2_AC1(kW)', 'z2_Light(kW)',\n","       'z2_Plug(kW)', 'z3_Light(kW)', 'z3_Plug(kW)', 'z4_AC1(kW)',\n","       'z4_Light(kW)', 'z4_Plug(kW)', 'z5_AC1(kW)', 'z5_Light(kW)',\n","       'z5_Plug(kW)', 'Year', 'Month', 'Day', 'Hour', 'Minute'],\n","      dtype='object')\n","(70459, 23)\n","Index(['total_demand', 'z1_AC1(kW)', 'z1_AC2(kW)', 'z1_AC3(kW)', 'z1_AC4(kW)',\n","       'z1_Light(kW)', 'z1_Plug(kW)', 'z2_AC1(kW)', 'z2_Light(kW)',\n","       'z2_Plug(kW)', 'z3_Light(kW)', 'z3_Plug(kW)', 'z4_AC1(kW)',\n","       'z4_Light(kW)', 'z4_Plug(kW)', 'z5_AC1(kW)', 'z5_Light(kW)',\n","       'z5_Plug(kW)', 'Year', 'Month', 'Day', 'Hour', 'Minute'],\n","      dtype='object')\n","(72613, 23)\n","Index(['total_demand', 'z1_AC1(kW)', 'z1_AC2(kW)', 'z1_AC3(kW)', 'z1_AC4(kW)',\n","       'z1_Light(kW)', 'z1_Plug(kW)', 'z2_AC1(kW)', 'z2_Light(kW)',\n","       'z2_Plug(kW)', 'z3_Light(kW)', 'z3_Plug(kW)', 'z4_AC1(kW)',\n","       'z4_Light(kW)', 'z4_Plug(kW)', 'z5_AC1(kW)', 'z5_Light(kW)',\n","       'z5_Plug(kW)', 'Year', 'Month', 'Day', 'Hour', 'Minute'],\n","      dtype='object')\n","(72859, 23)\n","Index(['total_demand', 'z1_AC1(kW)', 'z1_AC2(kW)', 'z1_AC3(kW)', 'z1_AC4(kW)',\n","       'z1_Light(kW)', 'z1_Plug(kW)', 'z2_AC1(kW)', 'z2_Light(kW)',\n","       'z2_Plug(kW)', 'z3_Light(kW)', 'z3_Plug(kW)', 'z4_AC1(kW)',\n","       'z4_Light(kW)', 'z4_Plug(kW)', 'z5_AC1(kW)', 'z5_Light(kW)',\n","       'z5_Plug(kW)', 'Year', 'Month', 'Day', 'Hour', 'Minute'],\n","      dtype='object')\n","(70725, 23)\n","Index(['total_demand', 'z1_AC1(kW)', 'z1_AC2(kW)', 'z1_AC3(kW)', 'z1_AC4(kW)',\n","       'z1_Light(kW)', 'z1_Plug(kW)', 'z2_AC1(kW)', 'z2_Light(kW)',\n","       'z2_Plug(kW)', 'z3_Light(kW)', 'z3_Plug(kW)', 'z4_AC1(kW)',\n","       'z4_Light(kW)', 'z4_Plug(kW)', 'z5_AC1(kW)', 'z5_Light(kW)',\n","       'z5_Plug(kW)', 'Year', 'Month', 'Day', 'Hour', 'Minute'],\n","      dtype='object')\n","(72833, 23)\n","Index(['total_demand', 'z1_AC1(kW)', 'z1_AC2(kW)', 'z1_AC3(kW)', 'z1_AC4(kW)',\n","       'z1_Light(kW)', 'z1_Plug(kW)', 'z2_AC1(kW)', 'z2_Light(kW)',\n","       'z2_Plug(kW)', 'z3_Light(kW)', 'z3_Plug(kW)', 'z4_AC1(kW)',\n","       'z4_Light(kW)', 'z4_Plug(kW)', 'z5_AC1(kW)', 'z5_Light(kW)',\n","       'z5_Plug(kW)', 'Year', 'Month', 'Day', 'Hour', 'Minute'],\n","      dtype='object')\n","(72780, 23)\n","Index(['total_demand', 'z1_AC1(kW)', 'z1_AC2(kW)', 'z1_AC3(kW)', 'z1_AC4(kW)',\n","       'z1_Light(kW)', 'z1_Plug(kW)', 'z2_AC1(kW)', 'z2_Light(kW)',\n","       'z2_Plug(kW)', 'z3_Light(kW)', 'z3_Plug(kW)', 'z4_AC1(kW)',\n","       'z4_Light(kW)', 'z4_Plug(kW)', 'z5_AC1(kW)', 'z5_Light(kW)',\n","       'z5_Plug(kW)', 'Year', 'Month', 'Day', 'Hour', 'Minute'],\n","      dtype='object')\n","(72185, 23)\n","Index(['total_demand', 'z1_AC1(kW)', 'z1_AC2(kW)', 'z1_AC3(kW)', 'z1_AC4(kW)',\n","       'z1_Light(kW)', 'z1_Plug(kW)', 'z2_AC1(kW)', 'z2_Light(kW)',\n","       'z2_Plug(kW)', 'z3_Light(kW)', 'z3_Plug(kW)', 'z4_AC1(kW)',\n","       'z4_Light(kW)', 'z4_Plug(kW)', 'z5_AC1(kW)', 'z5_Light(kW)',\n","       'z5_Plug(kW)', 'Year', 'Month', 'Day', 'Hour', 'Minute'],\n","      dtype='object')\n","(71707, 23)\n","Index(['total_demand', 'z1_AC1(kW)', 'z1_AC2(kW)', 'z1_AC3(kW)', 'z1_AC4(kW)',\n","       'z1_Light(kW)', 'z1_Plug(kW)', 'z2_AC1(kW)', 'z2_Light(kW)',\n","       'z2_Plug(kW)', 'z3_Light(kW)', 'z3_Plug(kW)', 'z4_AC1(kW)',\n","       'z4_Light(kW)', 'z4_Plug(kW)', 'z5_AC1(kW)', 'z5_Light(kW)',\n","       'z5_Plug(kW)', 'Year', 'Month', 'Day', 'Hour', 'Minute'],\n","      dtype='object')\n","(72862, 23)\n","Index(['total_demand', 'z1_AC1(kW)', 'z1_AC2(kW)', 'z1_AC3(kW)', 'z1_AC4(kW)',\n","       'z1_Light(kW)', 'z1_Plug(kW)', 'z2_AC1(kW)', 'z2_Light(kW)',\n","       'z2_Plug(kW)', 'z3_Light(kW)', 'z3_Plug(kW)', 'z4_AC1(kW)',\n","       'z4_Light(kW)', 'z4_Plug(kW)', 'z5_AC1(kW)', 'z5_Light(kW)',\n","       'z5_Plug(kW)', 'Year', 'Month', 'Day', 'Hour', 'Minute'],\n","      dtype='object')\n","(72777, 23)\n","Index(['total_demand', 'z1_AC1(kW)', 'z1_AC2(kW)', 'z1_AC3(kW)', 'z1_AC4(kW)',\n","       'z1_Light(kW)', 'z1_Plug(kW)', 'z2_AC1(kW)', 'z2_Light(kW)',\n","       'z2_Plug(kW)', 'z3_Light(kW)', 'z3_Plug(kW)', 'z4_AC1(kW)',\n","       'z4_Light(kW)', 'z4_Plug(kW)', 'z5_AC1(kW)', 'z5_Light(kW)',\n","       'z5_Plug(kW)', 'Year', 'Month', 'Day', 'Hour', 'Minute'],\n","      dtype='object')\n","(72339, 23)\n","Index(['total_demand', 'z1_AC1(kW)', 'z1_AC2(kW)', 'z1_AC3(kW)', 'z1_AC4(kW)',\n","       'z1_Light(kW)', 'z1_Plug(kW)', 'z2_AC1(kW)', 'z2_Light(kW)',\n","       'z2_Plug(kW)', 'z3_Light(kW)', 'z3_Plug(kW)', 'z4_AC1(kW)',\n","       'z4_Light(kW)', 'z4_Plug(kW)', 'z5_AC1(kW)', 'z5_Light(kW)',\n","       'z5_Plug(kW)', 'Year', 'Month', 'Day', 'Hour', 'Minute'],\n","      dtype='object')\n","(72864, 23)\n","Index(['total_demand', 'z1_AC1(kW)', 'z1_AC2(kW)', 'z1_AC3(kW)', 'z1_AC4(kW)',\n","       'z1_Light(kW)', 'z1_Plug(kW)', 'z2_AC1(kW)', 'z2_Light(kW)',\n","       'z2_Plug(kW)', 'z3_Light(kW)', 'z3_Plug(kW)', 'z4_AC1(kW)',\n","       'z4_Light(kW)', 'z4_Plug(kW)', 'z5_AC1(kW)', 'z5_Light(kW)',\n","       'z5_Plug(kW)', 'Year', 'Month', 'Day', 'Hour', 'Minute'],\n","      dtype='object')\n","(71774, 23)\n","Index(['total_demand', 'z1_AC1(kW)', 'z1_AC2(kW)', 'z1_AC3(kW)', 'z1_AC4(kW)',\n","       'z1_Light(kW)', 'z1_Plug(kW)', 'z2_AC1(kW)', 'z2_Light(kW)',\n","       'z2_Plug(kW)', 'z3_Light(kW)', 'z3_Plug(kW)', 'z4_AC1(kW)',\n","       'z4_Light(kW)', 'z4_Plug(kW)', 'z5_AC1(kW)', 'z5_Light(kW)',\n","       'z5_Plug(kW)', 'Year', 'Month', 'Day', 'Hour', 'Minute'],\n","      dtype='object')\n","(72864, 23)\n","Index(['total_demand', 'z1_AC1(kW)', 'z1_AC2(kW)', 'z1_AC3(kW)', 'z1_AC4(kW)',\n","       'z1_Light(kW)', 'z1_Plug(kW)', 'z2_AC1(kW)', 'z2_Light(kW)',\n","       'z2_Plug(kW)', 'z3_Light(kW)', 'z3_Plug(kW)', 'z4_AC1(kW)',\n","       'z4_Light(kW)', 'z4_Plug(kW)', 'z5_AC1(kW)', 'z5_Light(kW)',\n","       'z5_Plug(kW)', 'Year', 'Month', 'Day', 'Hour', 'Minute'],\n","      dtype='object')\n","(72864, 23)\n","Index(['total_demand', 'z1_AC1(kW)', 'z1_AC2(kW)', 'z1_AC3(kW)', 'z1_AC4(kW)',\n","       'z1_Light(kW)', 'z1_Plug(kW)', 'z2_AC1(kW)', 'z2_Light(kW)',\n","       'z2_Plug(kW)', 'z3_Light(kW)', 'z3_Plug(kW)', 'z4_AC1(kW)',\n","       'z4_Light(kW)', 'z4_Plug(kW)', 'z5_AC1(kW)', 'z5_Light(kW)',\n","       'z5_Plug(kW)', 'Year', 'Month', 'Day', 'Hour', 'Minute'],\n","      dtype='object')\n","(72864, 23)\n","Index(['total_demand', 'z1_AC1(kW)', 'z1_AC2(kW)', 'z1_AC3(kW)', 'z1_AC4(kW)',\n","       'z1_Light(kW)', 'z1_Plug(kW)', 'z2_AC1(kW)', 'z2_Light(kW)',\n","       'z2_Plug(kW)', 'z3_Light(kW)', 'z3_Plug(kW)', 'z4_AC1(kW)',\n","       'z4_Light(kW)', 'z4_Plug(kW)', 'z5_AC1(kW)', 'z5_Light(kW)',\n","       'z5_Plug(kW)', 'Year', 'Month', 'Day', 'Hour', 'Minute'],\n","      dtype='object')\n","(72832, 23)\n","Index(['total_demand', 'z1_AC1(kW)', 'z1_AC2(kW)', 'z1_AC3(kW)', 'z1_AC4(kW)',\n","       'z1_Light(kW)', 'z1_Plug(kW)', 'z2_AC1(kW)', 'z2_Light(kW)',\n","       'z2_Plug(kW)', 'z3_Light(kW)', 'z3_Plug(kW)', 'z4_AC1(kW)',\n","       'z4_Light(kW)', 'z4_Plug(kW)', 'z5_AC1(kW)', 'z5_Light(kW)',\n","       'z5_Plug(kW)', 'Year', 'Month', 'Day', 'Hour', 'Minute'],\n","      dtype='object')\n","(72864, 23)\n","Index(['total_demand', 'z1_AC1(kW)', 'z1_AC2(kW)', 'z1_AC3(kW)', 'z1_AC4(kW)',\n","       'z1_Light(kW)', 'z1_Plug(kW)', 'z2_AC1(kW)', 'z2_Light(kW)',\n","       'z2_Plug(kW)', 'z3_Light(kW)', 'z3_Plug(kW)', 'z4_AC1(kW)',\n","       'z4_Light(kW)', 'z4_Plug(kW)', 'z5_AC1(kW)', 'z5_Light(kW)',\n","       'z5_Plug(kW)', 'Year', 'Month', 'Day', 'Hour', 'Minute'],\n","      dtype='object')\n","(72383, 23)\n","Index(['total_demand', 'z1_AC1(kW)', 'z1_AC2(kW)', 'z1_AC3(kW)', 'z1_AC4(kW)',\n","       'z1_Light(kW)', 'z1_Plug(kW)', 'z2_AC1(kW)', 'z2_Light(kW)',\n","       'z2_Plug(kW)', 'z3_Light(kW)', 'z3_Plug(kW)', 'z4_AC1(kW)',\n","       'z4_Light(kW)', 'z4_Plug(kW)', 'z5_AC1(kW)', 'z5_Light(kW)',\n","       'z5_Plug(kW)', 'Year', 'Month', 'Day', 'Hour', 'Minute'],\n","      dtype='object')\n","(72864, 23)\n","Index(['total_demand', 'z1_AC1(kW)', 'z1_AC2(kW)', 'z1_AC3(kW)', 'z1_AC4(kW)',\n","       'z1_Light(kW)', 'z1_Plug(kW)', 'z2_AC1(kW)', 'z2_Light(kW)',\n","       'z2_Plug(kW)', 'z3_Light(kW)', 'z3_Plug(kW)', 'z4_AC1(kW)',\n","       'z4_Light(kW)', 'z4_Plug(kW)', 'z5_AC1(kW)', 'z5_Light(kW)',\n","       'z5_Plug(kW)', 'Year', 'Month', 'Day', 'Hour', 'Minute'],\n","      dtype='object')\n","(72642, 23)\n","Index(['total_demand', 'z1_AC1(kW)', 'z1_AC2(kW)', 'z1_AC3(kW)', 'z1_AC4(kW)',\n","       'z1_Light(kW)', 'z1_Plug(kW)', 'z2_AC1(kW)', 'z2_Light(kW)',\n","       'z2_Plug(kW)', 'z3_Light(kW)', 'z3_Plug(kW)', 'z4_AC1(kW)',\n","       'z4_Light(kW)', 'z4_Plug(kW)', 'z5_AC1(kW)', 'z5_Light(kW)',\n","       'z5_Plug(kW)', 'Year', 'Month', 'Day', 'Hour', 'Minute'],\n","      dtype='object')\n","(72863, 23)\n","Index(['total_demand', 'z1_AC1(kW)', 'z1_AC2(kW)', 'z1_AC3(kW)', 'z1_AC4(kW)',\n","       'z1_Light(kW)', 'z1_Plug(kW)', 'z2_AC1(kW)', 'z2_Light(kW)',\n","       'z2_Plug(kW)', 'z3_Light(kW)', 'z3_Plug(kW)', 'z4_AC1(kW)',\n","       'z4_Light(kW)', 'z4_Plug(kW)', 'z5_AC1(kW)', 'z5_Light(kW)',\n","       'z5_Plug(kW)', 'Year', 'Month', 'Day', 'Hour', 'Minute'],\n","      dtype='object')\n","(72754, 23)\n","Index(['total_demand', 'z1_AC1(kW)', 'z1_AC2(kW)', 'z1_AC3(kW)', 'z1_AC4(kW)',\n","       'z1_Light(kW)', 'z1_Plug(kW)', 'z2_AC1(kW)', 'z2_Light(kW)',\n","       'z2_Plug(kW)', 'z3_Light(kW)', 'z3_Plug(kW)', 'z4_AC1(kW)',\n","       'z4_Light(kW)', 'z4_Plug(kW)', 'z5_AC1(kW)', 'z5_Light(kW)',\n","       'z5_Plug(kW)', 'Year', 'Month', 'Day', 'Hour', 'Minute'],\n","      dtype='object')\n","(69129, 23)\n","Index(['total_demand', 'z1_AC1(kW)', 'z1_AC2(kW)', 'z1_AC3(kW)', 'z1_AC4(kW)',\n","       'z1_Light(kW)', 'z1_Plug(kW)', 'z2_AC1(kW)', 'z2_Light(kW)',\n","       'z2_Plug(kW)', 'z3_Light(kW)', 'z3_Plug(kW)', 'z4_AC1(kW)',\n","       'z4_Light(kW)', 'z4_Plug(kW)', 'z5_AC1(kW)', 'z5_Light(kW)',\n","       'z5_Plug(kW)', 'Year', 'Month', 'Day', 'Hour', 'Minute'],\n","      dtype='object')\n","(70094, 23)\n","Index(['total_demand', 'z1_AC1(kW)', 'z1_AC2(kW)', 'z1_AC3(kW)', 'z1_AC4(kW)',\n","       'z1_Light(kW)', 'z1_Plug(kW)', 'z2_AC1(kW)', 'z2_Light(kW)',\n","       'z2_Plug(kW)', 'z3_Light(kW)', 'z3_Plug(kW)', 'z4_AC1(kW)',\n","       'z4_Light(kW)', 'z4_Plug(kW)', 'z5_AC1(kW)', 'z5_Light(kW)',\n","       'z5_Plug(kW)', 'Year', 'Month', 'Day', 'Hour', 'Minute'],\n","      dtype='object')\n","(70151, 23)\n"]}],"source":["for _, df in dataframes.items():\n","    print(df.columns)\n","    print(df.shape)"]},{"cell_type":"markdown","id":"c7574d60-ad30-4735-b8f6-4d4fe1f6bee6","metadata":{"id":"c7574d60-ad30-4735-b8f6-4d4fe1f6bee6"},"source":["# Build the training set"]},{"cell_type":"code","execution_count":null,"id":"c7ec2dc2-848d-4316-8f30-77b89866bd5c","metadata":{"execution":{"iopub.execute_input":"2023-09-12T10:19:52.107393Z","iopub.status.busy":"2023-09-12T10:19:52.107393Z","iopub.status.idle":"2023-09-12T10:20:05.149906Z","shell.execute_reply":"2023-09-12T10:20:05.148588Z","shell.execute_reply.started":"2023-09-12T10:19:52.107393Z"},"id":"c7ec2dc2-848d-4316-8f30-77b89866bd5c","tags":[],"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713173699663,"user_tz":-120,"elapsed":107417,"user":{"displayName":"ff ff","userId":"03856258937076952853"}},"outputId":"592e7930-e98c-416d-c361-dcc1c9edf0ed"},"outputs":[{"output_type":"stream","name":"stdout","text":["(72774, 90, 23) (72774, 1)\n","(72774, 90, 23) (72774, 1)\n","(72774, 90, 23) (72774, 1)\n","(72774, 90, 23) (72774, 1)\n","(72774, 90, 23) (72774, 1)\n","(72774, 90, 23) (72774, 1)\n","(72774, 90, 23) (72774, 1)\n","(72774, 90, 23) (72774, 1)\n","(72774, 90, 23) (72774, 1)\n","(72774, 90, 23) (72774, 1)\n","(70809, 90, 23) (70809, 1)\n","(72774, 90, 23) (72774, 1)\n","(72748, 90, 23) (72748, 1)\n","(72771, 90, 23) (72771, 1)\n","(70369, 90, 23) (70369, 1)\n","(72523, 90, 23) (72523, 1)\n","(72769, 90, 23) (72769, 1)\n","(70635, 90, 23) (70635, 1)\n","(72743, 90, 23) (72743, 1)\n","(72690, 90, 23) (72690, 1)\n","(72095, 90, 23) (72095, 1)\n","(71617, 90, 23) (71617, 1)\n","(72772, 90, 23) (72772, 1)\n","(72687, 90, 23) (72687, 1)\n","(72249, 90, 23) (72249, 1)\n","(72774, 90, 23) (72774, 1)\n","(71684, 90, 23) (71684, 1)\n","(72774, 90, 23) (72774, 1)\n","(72774, 90, 23) (72774, 1)\n","(72774, 90, 23) (72774, 1)\n","(72742, 90, 23) (72742, 1)\n","(72774, 90, 23) (72774, 1)\n","(72293, 90, 23) (72293, 1)\n","(72774, 90, 23) (72774, 1)\n","(72552, 90, 23) (72552, 1)\n","(72773, 90, 23) (72773, 1)\n","(72664, 90, 23) (72664, 1)\n","(69039, 90, 23) (69039, 1)\n","(70004, 90, 23) (70004, 1)\n","(70061, 90, 23) (70061, 1)\n"]}],"source":["train_loader = []\n","test_loader = []\n","label_scalers = []\n","i= 0\n","for _, df in dataframes.items():\n","    inputs_cols_indices = range(0, df.shape[1])  # use (total_demand,Year,Month,Day,Hour,Minute) columns as features\n","    if i ==40:\n","      break\n","    #move the window\n","    inputs, labels = move_sliding_window(\n","        df.values,\n","        window_size,\n","        inputs_cols_indices=inputs_cols_indices,\n","        label_col_index=label_col_index\n","    )\n","\n","    # Normalize the input data columns\n","    sc = MinMaxScaler()\n","    # Obtaining the scaler for the labels(usage data) so that output can be re-scaled to actual value during evaluation\n","    label_sc = MinMaxScaler()\n","\n","    # Split data into train/test portions and combining all data into a single array\n","    test_portion = int(0.2 * len(inputs))\n","\n","    train_x = sc.fit_transform(inputs[:-test_portion].reshape(-1, window_size * df.shape[1]))\n","    train_x = train_x.reshape(-1, window_size, df.shape[1])\n","    train_y = label_sc.fit_transform(labels[:-test_portion])\n","\n","    test_x = sc.transform(inputs[-test_portion:].reshape(-1, window_size * df.shape[1]))\n","    test_x = test_x.reshape(-1, window_size, df.shape[1])\n","    test_y = label_sc.transform(labels[-test_portion:])\n","\n","    # test_x.append(testx)\n","    # test_y.append(testy)\n","    label_scalers.append(label_sc)\n","\n","    # pytorch data loaders\n","    train_data = TensorDataset(torch.from_numpy(train_x).to('cpu'), torch.from_numpy(train_y).to('cpu'))\n","    train_loader.append(DataLoader(train_data, batch_size=batch_size, drop_last=True))# Drop the last incomplete batch\n","    test_data = TensorDataset(torch.from_numpy(test_x).to('cpu'), torch.from_numpy(test_y).to('cpu'))\n","    test_loader.append(DataLoader(test_data, batch_size=batch_size))# Drop the last incomplete batch\n","\n","    # release some memory\n","    del train_x, train_y\n","    i=i+1\n","\n","input_dim = next(iter(train_loader[0]))[0].shape[2]  # 22"]},{"cell_type":"markdown","id":"2ca3a158-c53d-4e1a-a73c-fe2c2dc7b458","metadata":{"id":"2ca3a158-c53d-4e1a-a73c-fe2c2dc7b458"},"source":["# LSTM model"]},{"cell_type":"code","execution_count":null,"id":"47d095c5-331b-4ae9-8b8d-570ab5a4fa3d","metadata":{"execution":{"iopub.execute_input":"2023-09-12T10:20:05.156907Z","iopub.status.busy":"2023-09-12T10:20:05.155907Z","iopub.status.idle":"2023-09-12T10:20:05.212920Z","shell.execute_reply":"2023-09-12T10:20:05.211919Z","shell.execute_reply.started":"2023-09-12T10:20:05.156907Z"},"id":"47d095c5-331b-4ae9-8b8d-570ab5a4fa3d","tags":[],"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713173699663,"user_tz":-120,"elapsed":3,"user":{"displayName":"ff ff","userId":"03856258937076952853"}},"outputId":"c75049da-a050-44e5-885a-d8cbafcae81e"},"outputs":[{"output_type":"stream","name":"stdout","text":["LSTMNet(\n","  (lstm): LSTM(23, 256, num_layers=2, batch_first=True, dropout=0.2)\n","  (fc): Linear(in_features=256, out_features=1, bias=True)\n","  (relu): ReLU()\n",")\n","814337\n"]}],"source":["lstm = LSTMNet(input_dim, hidden_dim, output_dim, n_layers)\n","model_type = 'LSTM'\n","print(lstm)\n","print(num_params(lstm))"]},{"cell_type":"markdown","id":"J8W4MvgvhHEP","metadata":{"id":"J8W4MvgvhHEP"},"source":["## FedAvg"]},{"cell_type":"code","execution_count":12,"id":"2a6dcbfb-f06f-4f3e-90db-076e5e96f80d","metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2023-09-11T10:18:22.822003Z","iopub.status.busy":"2023-09-11T10:18:22.822003Z","iopub.status.idle":"2023-09-11T18:29:50.783079Z","shell.execute_reply":"2023-09-11T18:29:50.783079Z","shell.execute_reply.started":"2023-09-11T10:18:22.822003Z"},"id":"2a6dcbfb-f06f-4f3e-90db-076e5e96f80d","jupyter":{"outputs_hidden":true},"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f8a46e69-ec11-4167-863c-d9d8641fe74b","executionInfo":{"status":"ok","timestamp":1713189593913,"user_tz":-120,"elapsed":13192214,"user":{"displayName":"ff ff","userId":"03856258937076952853"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","round 43, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.0006498759913873595\n","round 43, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.009406428268578437\n","round 43, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.004971711621952378\n","round 43, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 6.106329066659039e-05\n","round 43, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.0006554384854098316\n","round 43, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.702796701394618e-05\n","round 43, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.64234085051742e-05\n","round 43, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.00013551649964129963\n","round 43, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.0001348984034409893\n","round 43, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 8.540879736886251e-05\n","round 43, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.0003303625036964645\n","round 43, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.613082040362184e-05\n","round 43, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.00012179240468412898\n","round 43, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 9.495025771652114e-05\n","round 43, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 8.641547171299118e-05\n","round 43, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.0004481265251732631\n","round 43, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.000147114608596764\n","round 43, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 7.093251004367371e-05\n","round 43, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.0008174710830124762\n","round 43, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.48966632833695e-05\n","round 43, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.0005782029212631251\n","round 43, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.00015323267832302787\n","round 43, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.0005742350666488554\n","round 43, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 0.00010519121029314451\n","round 43, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.0005588875584570424\n","round 43, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 6.623066722357048e-05\n","round 43, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.0005341856277872076\n","round 43, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.00016606370268894868\n","round 43, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.00013640640593491423\n","round 43, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 0.00010790322122440037\n","round 43, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.00016071496527746485\n","round 43, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.00011018916071676628\n","round 43, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.00022566133999067398\n","calc smape: 49.807733684959736%\n","MAE: 58.019014618167304\n","RMSE: 187.33711645945525\n","Average Loss:  0.00454221456470415\n","\n","starting avg round 44\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 44, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.007070222636684776\n","round 44, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.004238412682233113\n","round 44, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.0036410326013408072\n","round 44, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.007132085273042322\n","round 44, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.004524182773561085\n","round 44, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.002283345814378533\n","round 44, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.008977411514414207\n","round 44, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.0006472350510843432\n","round 44, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.009378255178619706\n","round 44, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.004996772186132147\n","round 44, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 6.210640004114378e-05\n","round 44, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.0006528068648289523\n","round 44, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.662279148500861e-05\n","round 44, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.583698745098185e-05\n","round 44, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.00013666587144851088\n","round 44, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.00013674392202541897\n","round 44, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 8.781638419869914e-05\n","round 44, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.0003328045940344799\n","round 44, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.842340935912424e-05\n","round 44, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.00012332600096799849\n","round 44, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 9.867543867260662e-05\n","round 44, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 8.666724356771736e-05\n","round 44, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.0004430239062328059\n","round 44, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.00014646971737874987\n","round 44, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 7.262507166875106e-05\n","round 44, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.0008076415249109105\n","round 44, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.588490097263795e-05\n","round 44, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.0005828703056717391\n","round 44, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.00015126511880225735\n","round 44, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.0005642226029262279\n","round 44, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 0.00010549296174693673\n","round 44, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.0005527211526766353\n","round 44, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 6.627905898426432e-05\n","round 44, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.000524190545028042\n","round 44, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.00017106593434488917\n","round 44, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.00013039553485733838\n","round 44, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 0.00011816676949852731\n","round 44, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.00016169324312871155\n","round 44, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.00011070759839000216\n","round 44, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.00022766134242778612\n","calc smape: 49.08630078489886%\n","MAE: 53.78909283087292\n","RMSE: 184.16671837749794\n","Average Loss:  0.004358261663329694\n","\n","starting avg round 45\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 45, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.006972401444467583\n","round 45, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.004148665428926636\n","round 45, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.0036515527005706516\n","round 45, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.007113588208864843\n","round 45, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.0045165444857307845\n","round 45, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.0022030551626812667\n","round 45, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.008915379460501884\n","round 45, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.0006275502047563869\n","round 45, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.009323758937950646\n","round 45, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.0049552098956025595\n","round 45, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 6.0756735642412816e-05\n","round 45, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.0006120125555233762\n","round 45, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.772697534300668e-05\n","round 45, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.580918062493373e-05\n","round 45, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.00013494908935424767\n","round 45, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.00013820749161855668\n","round 45, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 8.538284750362176e-05\n","round 45, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.00033268257564652063\n","round 45, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.667902950078703e-05\n","round 45, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.00011958911267941274\n","round 45, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 0.0001014334951849248\n","round 45, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 8.60653739519793e-05\n","round 45, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.00043680855872350687\n","round 45, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.00014353230324104516\n","round 45, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 7.103017080315306e-05\n","round 45, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.0007930633772567877\n","round 45, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.490873052809678e-05\n","round 45, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.0005391403701651142\n","round 45, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.0001508110238189277\n","round 45, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.00056755173500278\n","round 45, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 0.00010627634731008587\n","round 45, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.0005388952454917932\n","round 45, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 6.783381118680154e-05\n","round 45, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.0005267872108691205\n","round 45, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.00017333689100951233\n","round 45, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.00012874103991375053\n","round 45, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 0.00011227192394309373\n","round 45, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.00016092600712651787\n","round 45, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.00011053469565754143\n","round 45, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.00022480263330887986\n","calc smape: 49.183491751692834%\n","MAE: 54.315419165272594\n","RMSE: 184.48220828920554\n","Average Loss:  0.004479242521828998\n","\n","starting avg round 46\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 46, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.007033167988993229\n","round 46, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.004228388844889455\n","round 46, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.003651989220608292\n","round 46, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.007137290335127281\n","round 46, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.00442740832139472\n","round 46, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.002213612088650864\n","round 46, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.008895921878450147\n","round 46, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.000670313148345615\n","round 46, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.009348204700342777\n","round 46, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.0049319567998671624\n","round 46, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 6.112709157109336e-05\n","round 46, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.0006169138141558503\n","round 46, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.601384040370249e-05\n","round 46, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.59728548343576e-05\n","round 46, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.00013501542863886477\n","round 46, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.00013561365569866472\n","round 46, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 8.383835812050425e-05\n","round 46, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.00032969269126707253\n","round 46, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.783398887261033e-05\n","round 46, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.00012363442208749933\n","round 46, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 9.91176393857326e-05\n","round 46, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 8.582393901716303e-05\n","round 46, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.0004375952100547563\n","round 46, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.00014412193783235646\n","round 46, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 7.13704245640656e-05\n","round 46, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.0007963717104887889\n","round 46, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.509673028582646e-05\n","round 46, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.0005699129802191498\n","round 46, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.00014743373945488462\n","round 46, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.0005730103579740641\n","round 46, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 0.00011376781008363781\n","round 46, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.0005486826926893885\n","round 46, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 6.732776854992803e-05\n","round 46, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.0005279880211414171\n","round 46, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.00016692491188255838\n","round 46, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.00013337514389734546\n","round 46, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 0.00010576806386097815\n","round 46, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.00016123317244098458\n","round 46, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.000109426446998542\n","round 46, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.00022576358810511008\n","calc smape: 48.88611524649311%\n","MAE: 52.85361593849313\n","RMSE: 183.50826393596384\n","Average Loss:  0.004317467033498523\n","\n","starting avg round 47\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 47, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.00700370895044346\n","round 47, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.0041822091526617965\n","round 47, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.003659813020411613\n","round 47, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.007086153508030944\n","round 47, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.00449248604958744\n","round 47, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.0022163269043500937\n","round 47, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.008954260764377456\n","round 47, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.000621325502704297\n","round 47, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.009322409343440086\n","round 47, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.004937648490470438\n","round 47, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 6.064709476215118e-05\n","round 47, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.0006117394625886975\n","round 47, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.62732432343468e-05\n","round 47, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.48858713970029e-05\n","round 47, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.0001344545128261045\n","round 47, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.00013578096940948726\n","round 47, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 8.488590635481941e-05\n","round 47, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.0003291843796432658\n","round 47, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.593159110668888e-05\n","round 47, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.00012261882258306805\n","round 47, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 9.348506090743418e-05\n","round 47, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 8.571657485845208e-05\n","round 47, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.00042400358714595707\n","round 47, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.00014358386600373964\n","round 47, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 7.146459761031565e-05\n","round 47, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.0007748588614049368\n","round 47, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.470365698468023e-05\n","round 47, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.0005273866091946337\n","round 47, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.00014973681975659144\n","round 47, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.0005482127154599377\n","round 47, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 0.00010370839113095697\n","round 47, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.0005184974270378007\n","round 47, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 6.573307157558311e-05\n","round 47, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.0004969712491791663\n","round 47, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.00016877068588071003\n","round 47, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.0001209540745808876\n","round 47, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 0.0001223362198337392\n","round 47, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.00016038132372279572\n","round 47, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.00010916343675220291\n","round 47, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.0002243383137115247\n","calc smape: 49.375953603645996%\n","MAE: 55.03135901559564\n","RMSE: 184.84508307398602\n","Average Loss:  0.004441208765473737\n","\n","starting avg round 48\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 48, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.007002698698280646\n","round 48, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.004181161290034652\n","round 48, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.003639383536730228\n","round 48, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.007071392128377087\n","round 48, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.004469334002351388\n","round 48, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.0022165170500686934\n","round 48, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.00888261682952621\n","round 48, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.0006193828591806644\n","round 48, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.0092942719347775\n","round 48, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.004885648639174177\n","round 48, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 6.093123500001888e-05\n","round 48, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.0006179920715762172\n","round 48, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.657639494455777e-05\n","round 48, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.553949256232172e-05\n","round 48, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.00013456487342274935\n","round 48, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.00013739746232691426\n","round 48, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 8.585015130587896e-05\n","round 48, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.00033021180907904954\n","round 48, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.785236503440892e-05\n","round 48, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.00012458886387126507\n","round 48, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 9.50956666575361e-05\n","round 48, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 8.608691428807189e-05\n","round 48, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.00043664824495083716\n","round 48, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.00014503494745505516\n","round 48, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 7.213256692547734e-05\n","round 48, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.0007982348597579403\n","round 48, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.51495589067963e-05\n","round 48, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.0005163685052268973\n","round 48, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.0001478965800743026\n","round 48, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.0005567678105892681\n","round 48, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 9.390444022626202e-05\n","round 48, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.0005272922236534735\n","round 48, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 6.610712516216413e-05\n","round 48, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.0005213583712507637\n","round 48, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.00016829662987610005\n","round 48, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.0001223900365273169\n","round 48, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 0.00011907845368698742\n","round 48, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.00016091964198923682\n","round 48, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.00010994123772434249\n","round 48, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.00022398088188950812\n","calc smape: 48.680171184937706%\n","MAE: 51.48745320195649\n","RMSE: 182.47805291048596\n","Average Loss:  0.004349317537518242\n","\n","starting avg round 49\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 49, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.0069592567493340805\n","round 49, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.0041566919327513975\n","round 49, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.0036083061921609837\n","round 49, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.007024131374367112\n","round 49, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.004418065322430005\n","round 49, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.002214767288283577\n","round 49, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.008861832021336473\n","round 49, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.0005961836559436051\n","round 49, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.009353718703745732\n","round 49, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.004886002766267796\n","round 49, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 6.0271906291249736e-05\n","round 49, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.0006084755810401736\n","round 49, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.666855515113509e-05\n","round 49, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.555325217773705e-05\n","round 49, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.00013384713017953968\n","round 49, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.00013257583661844104\n","round 49, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 8.4359753697884e-05\n","round 49, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.00032832099105607163\n","round 49, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.505337160525025e-05\n","round 49, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.0001187341773142439\n","round 49, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 9.328908185222775e-05\n","round 49, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 8.590361992239856e-05\n","round 49, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.00042389124921880594\n","round 49, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.0001391917630663946\n","round 49, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 7.11660780479763e-05\n","round 49, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.0007616215648990225\n","round 49, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.491342441807187e-05\n","round 49, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.0005185644851215848\n","round 49, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.00015005140559359075\n","round 49, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.0005405457910196025\n","round 49, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 0.00010626200030726198\n","round 49, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.0005019099291010727\n","round 49, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 6.446350212334957e-05\n","round 49, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.0005081229997553498\n","round 49, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.0001635529285246256\n","round 49, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.0001231089436259936\n","round 49, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 0.0001137127054075141\n","round 49, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.00016063797431154354\n","round 49, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.00010943384156100229\n","round 49, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.00022281539389513015\n","calc smape: 49.296671432500624%\n","MAE: 54.65696985814995\n","RMSE: 184.69131446567707\n","Average Loss:  0.004395723345025521\n","\n","starting avg round 50\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 50, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.006985960386893048\n","round 50, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.004185212846745604\n","round 50, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.003619092038466728\n","round 50, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.007078219379764051\n","round 50, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.004421657279765764\n","round 50, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.0022181942185852672\n","round 50, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.008904681075364353\n","round 50, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.0006030011535196016\n","round 50, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.009321500846583928\n","round 50, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.004937367222737521\n","round 50, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 6.16349999993624e-05\n","round 50, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.0005984194223336609\n","round 50, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.637314826335829e-05\n","round 50, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.723323486581129e-05\n","round 50, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.0001344957024095358\n","round 50, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.0001334692905905805\n","round 50, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 8.428957510529597e-05\n","round 50, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.00033127544066825396\n","round 50, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.729204668929015e-05\n","round 50, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.0001234801139357192\n","round 50, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 9.554084856639682e-05\n","round 50, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 8.608951337588554e-05\n","round 50, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.00042105963283185186\n","round 50, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.00014178988083455937\n","round 50, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 7.155867008431674e-05\n","round 50, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.0007936791249189157\n","round 50, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.493680727511933e-05\n","round 50, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.000543439180286701\n","round 50, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.00014830531238528368\n","round 50, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.0005499519375007369\n","round 50, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 0.00011328339275808374\n","round 50, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.0005172635833982246\n","round 50, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 6.554193753264111e-05\n","round 50, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.0005149601596973037\n","round 50, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.00016782751099039418\n","round 50, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.00012433186436412925\n","round 50, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 0.00010837672543370248\n","round 50, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.0001601815480291475\n","round 50, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.00010937380323883662\n","round 50, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.00022882113386946942\n","calc smape: 48.58959971273001%\n","MAE: 50.6663073139524\n","RMSE: 181.835930460966\n","Average Loss:  0.004382544311862923\n","\n","starting avg round 51\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 51, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.006990272269052055\n","round 51, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.004133836324659309\n","round 51, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.003545466619211116\n","round 51, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.007007057537391249\n","round 51, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.00443164018049304\n","round 51, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.0022106853014390374\n","round 51, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.008871475899858134\n","round 51, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.0005739585428403056\n","round 51, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.009270079167825835\n","round 51, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.004868506279308349\n","round 51, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 6.026572691553155e-05\n","round 51, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.0006112068513175472\n","round 51, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.5449287930361084e-05\n","round 51, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.489387629837958e-05\n","round 51, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.00013411015958421629\n","round 51, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.00013243158082332227\n","round 51, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 8.235146336638928e-05\n","round 51, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.0003374292036203934\n","round 51, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.43825216056991e-05\n","round 51, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.00011820113304241074\n","round 51, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 9.208051995658804e-05\n","round 51, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 8.567572829385674e-05\n","round 51, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.0004203612037859523\n","round 51, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.0001394562809926875\n","round 51, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 7.076858661443048e-05\n","round 51, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.000774292014414511\n","round 51, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.455574821018217e-05\n","round 51, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.0005500407982513675\n","round 51, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.0001433765579089855\n","round 51, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.0005359091303814368\n","round 51, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 0.00010545280679252757\n","round 51, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.0005160475619569686\n","round 51, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 6.61290281535847e-05\n","round 51, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.0005256222513188342\n","round 51, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.000160784412823237\n","round 51, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.00012362707697580584\n","round 51, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 0.00012696366971048126\n","round 51, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.00016051349126977382\n","round 51, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.00010964773271435088\n","round 51, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.00022320138854141716\n","calc smape: 48.86924501262139%\n","MAE: 51.99704802257746\n","RMSE: 182.73063920957543\n","Average Loss:  0.004461973056741142\n","\n","starting avg round 52\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 52, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.006967304532216597\n","round 52, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.004185739775753714\n","round 52, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.0035951486996574594\n","round 52, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.0070184116318289715\n","round 52, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.004473183832098065\n","round 52, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.0022136982879601423\n","round 52, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.008906047525150437\n","round 52, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.0006557782505426858\n","round 52, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.009277667351333153\n","round 52, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.00490759396260338\n","round 52, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 6.024926550377462e-05\n","round 52, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.0006321996897895584\n","round 52, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.576487512914744e-05\n","round 52, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.483706232440974e-05\n","round 52, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.00013324692800206658\n","round 52, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.00013299757392815081\n","round 52, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 8.24455998359294e-05\n","round 52, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.0003286822768069958\n","round 52, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.355578369455284e-05\n","round 52, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.00012021733079693931\n","round 52, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 9.371087570895854e-05\n","round 52, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 8.562222123228736e-05\n","round 52, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.00041559443031603983\n","round 52, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.00014366885471060544\n","round 52, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 6.994989094875694e-05\n","round 52, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.000760596070904285\n","round 52, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.444998028395535e-05\n","round 52, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.0005744657009927322\n","round 52, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.00014316634035692135\n","round 52, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.000537227530523004\n","round 52, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 0.00011372974144511056\n","round 52, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.0005252451090720048\n","round 52, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 6.478657838978766e-05\n","round 52, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.0005185920781514142\n","round 52, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.000161262276760356\n","round 52, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.00012530118621205993\n","round 52, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 0.0001046164744756035\n","round 52, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.00016067436972833714\n","round 52, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.00010914042904577971\n","round 52, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.00022317479899222097\n","calc smape: 48.789740325047774%\n","MAE: 51.511827182283476\n","RMSE: 182.3320990769465\n","Average Loss:  0.004354153508211446\n","\n","starting avg round 53\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 53, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.0069428319277773974\n","round 53, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.004131843435711093\n","round 53, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.003581904024550957\n","round 53, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.007014886118538147\n","round 53, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.004391109612437761\n","round 53, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.002240465299109928\n","round 53, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.008855354589676219\n","round 53, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.0006030488867898901\n","round 53, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.00929793364567948\n","round 53, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.0048907360386302974\n","round 53, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 6.000371742051026e-05\n","round 53, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.0006359264480124693\n","round 53, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.53082018988685e-05\n","round 53, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.504630996533836e-05\n","round 53, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.0001309439251355326\n","round 53, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.0001318401749910793\n","round 53, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 8.319742317196093e-05\n","round 53, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.00032922592523722087\n","round 53, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.428481330685048e-05\n","round 53, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.00011900817430289733\n","round 53, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 8.794702293560672e-05\n","round 53, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 8.506996034818504e-05\n","round 53, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.0004107164118717526\n","round 53, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.000149039012252875\n","round 53, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 7.006126144558169e-05\n","round 53, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.0007771971203120691\n","round 53, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.418360834459236e-05\n","round 53, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.0005558603050823355\n","round 53, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.00014441445091506466\n","round 53, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.0005299346474722759\n","round 53, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 0.0001091826913060296\n","round 53, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.0004975341094645305\n","round 53, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 6.501028293623025e-05\n","round 53, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.0004906984642210383\n","round 53, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.0001639361179124015\n","round 53, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.00012139577886825594\n","round 53, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 0.00013122758124544428\n","round 53, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.00016011900066278376\n","round 53, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.00010856433368644501\n","round 53, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.00022328875393719092\n","calc smape: 48.8227810687432%\n","MAE: 51.067669029377825\n","RMSE: 181.97186396479032\n","Average Loss:  0.004429514377267475\n","\n","starting avg round 54\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 54, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.00697352391268526\n","round 54, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.004183319384797608\n","round 54, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.003497122150812564\n","round 54, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.0070106172851020715\n","round 54, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.004382209236999708\n","round 54, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.0021852326047207627\n","round 54, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.008844895471286562\n","round 54, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.0006227876495229013\n","round 54, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.00925223359705082\n","round 54, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.004871570347209595\n","round 54, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 5.9286375475990504e-05\n","round 54, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.0006326357514418693\n","round 54, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.5994529833543704e-05\n","round 54, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.611793353134999e-05\n","round 54, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.00013183143681561445\n","round 54, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.00012909916487810084\n","round 54, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 8.244615667406054e-05\n","round 54, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.00032916881200435445\n","round 54, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.688727108628621e-05\n","round 54, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.00013159476460649394\n","round 54, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 9.172845321765115e-05\n","round 54, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 8.321815165469491e-05\n","round 54, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.00042016338816860553\n","round 54, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.00014988983337259148\n","round 54, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 7.01278114324363e-05\n","round 54, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.0007421847609033911\n","round 54, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.390046425508444e-05\n","round 54, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.0005272233177363105\n","round 54, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.00014057573590824698\n","round 54, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.0005513761820371395\n","round 54, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 0.0001017895159358367\n","round 54, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.0005032382669014623\n","round 54, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 6.290256807720392e-05\n","round 54, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.0004992774647689656\n","round 54, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.0001824203709881138\n","round 54, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.00012110998250136618\n","round 54, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 0.0001115090907351909\n","round 54, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.00016019379224314244\n","round 54, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.00010828573025449896\n","round 54, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.00022326841177447128\n","calc smape: 48.53851923553519%\n","MAE: 49.95463257941365\n","RMSE: 181.18474705412567\n","Average Loss:  0.0043038853067043775\n","\n","starting avg round 55\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 55, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.006906956874965023\n","round 55, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.0041260179589569035\n","round 55, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.003493251632400123\n","round 55, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.0069710085767188245\n","round 55, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.0043366496060376165\n","round 55, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.002161931533399702\n","round 55, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.00884745953538056\n","round 55, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.0006036911797439513\n","round 55, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.009295282652601601\n","round 55, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.004878121740018417\n","round 55, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 6.0337053016403586e-05\n","round 55, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.0005662933311084219\n","round 55, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.578300935723486e-05\n","round 55, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.654433646361473e-05\n","round 55, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.0001307890066881454\n","round 55, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.00013190198305729995\n","round 55, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 8.33364677289085e-05\n","round 55, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.0003289446596475253\n","round 55, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.59235279976513e-05\n","round 55, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.00012160753616236822\n","round 55, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 9.370877877959826e-05\n","round 55, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 8.495267789757317e-05\n","round 55, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.00041901533040800126\n","round 55, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.0001482623588831952\n","round 55, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 6.988368034756474e-05\n","round 55, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.0007012706092999516\n","round 55, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.496123895008817e-05\n","round 55, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.0004998929653083906\n","round 55, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.0001411219365244116\n","round 55, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.0005334527553973854\n","round 55, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 0.00010159553088279999\n","round 55, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.000510545465398796\n","round 55, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 8.009055750741416e-05\n","round 55, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.0005075872826897207\n","round 55, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.00016495487082173504\n","round 55, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.00012050217511776804\n","round 55, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 0.00010729815496038747\n","round 55, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.00015983606140424563\n","round 55, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.00010747831628645212\n","round 55, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.0002222332327198307\n","calc smape: 48.885957379925756%\n","MAE: 51.42374321077025\n","RMSE: 181.9919093105956\n","Average Loss:  0.004419596849222311\n","\n","starting avg round 56\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 56, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.006902284920215606\n","round 56, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.004147921693012385\n","round 56, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.0034793499466364403\n","round 56, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.006984531347240723\n","round 56, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.00438036728467393\n","round 56, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.0021879173831881155\n","round 56, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.00887157898562561\n","round 56, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.0006455220017025048\n","round 56, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.009279254640984749\n","round 56, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.004858201132654876\n","round 56, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 5.873352591317432e-05\n","round 56, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.0005886680597281419\n","round 56, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.608287869294664e-05\n","round 56, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.546075768719415e-05\n","round 56, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.0001314198345544018\n","round 56, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.00013984761236786523\n","round 56, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 8.286801448775806e-05\n","round 56, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.00032878454847336383\n","round 56, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.630771048055716e-05\n","round 56, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.00012473737115215047\n","round 56, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 9.327159943950392e-05\n","round 56, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 8.302697584771192e-05\n","round 56, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.00041702555530978965\n","round 56, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.00013597412912044353\n","round 56, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 6.879517916250473e-05\n","round 56, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.0007468777340753669\n","round 56, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.422151304669959e-05\n","round 56, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.0005086588470086487\n","round 56, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.00014147745962743232\n","round 56, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.0005314415024518631\n","round 56, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 9.479163518985188e-05\n","round 56, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.00047099301108184064\n","round 56, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 6.588469113515721e-05\n","round 56, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.0004974953517375977\n","round 56, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.00016516996862898331\n","round 56, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.00011466463755433714\n","round 56, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 0.00010648452132500096\n","round 56, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.00015966891449369425\n","round 56, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.00010845960789791002\n","round 56, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.00022120200510808327\n","calc smape: 48.61179899922479%\n","MAE: 50.11379121288127\n","RMSE: 181.28834470174266\n","Average Loss:  0.004335246264922347\n","\n","starting avg round 57\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 57, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.006862332952940572\n","round 57, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.004080697195604443\n","round 57, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.0034731599028288785\n","round 57, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.006975014585935115\n","round 57, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.004320748852998285\n","round 57, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.002193592783961711\n","round 57, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.008832598903349463\n","round 57, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.0006136178664226982\n","round 57, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.009253642239075686\n","round 57, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.004889436627438822\n","round 57, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 5.9379613365060574e-05\n","round 57, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.0005502169749109138\n","round 57, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.716656235359551e-05\n","round 57, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.608472877304198e-05\n","round 57, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.00012919966707158892\n","round 57, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.00012877915603277352\n","round 57, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 8.197623878913875e-05\n","round 57, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.0003305731053925145\n","round 57, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.551811349086036e-05\n","round 57, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.0001291875066889198\n","round 57, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 9.103504359586623e-05\n","round 57, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 8.319169643817241e-05\n","round 57, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.0004186838606463945\n","round 57, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.00014911593853282411\n","round 57, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 6.907265462327164e-05\n","round 57, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.0007317610002896148\n","round 57, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.431216920483556e-05\n","round 57, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.0005492903292179107\n","round 57, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.00014091682935811286\n","round 57, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.0004959555998149361\n","round 57, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 0.00010275635366139924\n","round 57, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.0004877231770348902\n","round 57, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 6.364537853796393e-05\n","round 57, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.0004943326545929137\n","round 57, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.00015779951356924876\n","round 57, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.00011846240639507801\n","round 57, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 0.00010574843802097738\n","round 57, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.00016024128928689122\n","round 57, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.00010782997131813049\n","round 57, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.0002221828856531997\n","calc smape: 48.671535638773825%\n","MAE: 50.560145854207306\n","RMSE: 181.4097598654707\n","Average Loss:  0.0042890040769337\n","\n","starting avg round 58\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 58, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.006861622927577366\n","round 58, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.004096952994586901\n","round 58, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.0035045985381917224\n","round 58, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.006987601327377236\n","round 58, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.004338107512532067\n","round 58, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.002098753077526843\n","round 58, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.00884875113011471\n","round 58, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.0006433138553672638\n","round 58, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.009217562702750523\n","round 58, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.004846478953757988\n","round 58, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 5.9898936032451196e-05\n","round 58, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.0005332904708796247\n","round 58, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.6442656306615906e-05\n","round 58, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.728948388116155e-05\n","round 58, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.00013260745434232982\n","round 58, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.00013351312556356528\n","round 58, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 8.17205217832192e-05\n","round 58, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.0003291261470415272\n","round 58, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.416784056221722e-05\n","round 58, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.00012364784000900333\n","round 58, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 8.604376654375298e-05\n","round 58, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 8.462734864141648e-05\n","round 58, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.0004107560632421934\n","round 58, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.00014993167162304284\n","round 58, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 7.106207256616211e-05\n","round 58, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.0006783877220836336\n","round 58, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.414240789760177e-05\n","round 58, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.00047489239737582726\n","round 58, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.00014150473329469347\n","round 58, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.0005049988638867424\n","round 58, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 9.393286898427635e-05\n","round 58, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.00045198391282091113\n","round 58, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 6.460264683434096e-05\n","round 58, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.0005031244116772933\n","round 58, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.00016445406275319586\n","round 58, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.0001159912426373921\n","round 58, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 0.00010640811968544637\n","round 58, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.0001600478469668506\n","round 58, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.00010833581957622638\n","round 58, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.00022330871964489535\n","calc smape: 48.797724074609356%\n","MAE: 50.7553141407982\n","RMSE: 181.27591034512457\n","Average Loss:  0.004491683610139039\n","\n","starting avg round 59\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 59, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.006914717968486782\n","round 59, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.00410825791602422\n","round 59, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.003469422995944374\n","round 59, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.006979863907742712\n","round 59, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.004339210680752461\n","round 59, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.002132167287137626\n","round 59, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.008821196163937978\n","round 59, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.0006295969750291468\n","round 59, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.009214537958281912\n","round 59, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.004893337563511782\n","round 59, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 5.893484020899368e-05\n","round 59, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.0005481356230510366\n","round 59, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.633659634529457e-05\n","round 59, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.622409412176368e-05\n","round 59, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.00012899884374022535\n","round 59, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.0001296374925386447\n","round 59, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 8.043335381963907e-05\n","round 59, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.00032686279630731656\n","round 59, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.537720666230595e-05\n","round 59, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.00012590132499618842\n","round 59, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 8.900564100144948e-05\n","round 59, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 8.373716163160596e-05\n","round 59, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.0004108708539466273\n","round 59, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.00013490176373969528\n","round 59, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 7.213144046350602e-05\n","round 59, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.000688542384783172\n","round 59, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.408294924702724e-05\n","round 59, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.0005316820172863248\n","round 59, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.00013967652557767002\n","round 59, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.0005205046353304559\n","round 59, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 0.00010485934253015979\n","round 59, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.0004608438266586743\n","round 59, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 6.213174728486592e-05\n","round 59, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.00047264302390561015\n","round 59, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.0001613634757079905\n","round 59, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.00011901215650920805\n","round 59, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 0.00010511268936852501\n","round 59, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.00016007612984105673\n","round 59, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.00010720763100801345\n","round 59, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.00021977463777350043\n","calc smape: 48.92181412503634%\n","MAE: 51.81673046817829\n","RMSE: 182.02783413138667\n","Average Loss:  0.004359851004231358\n","\n","starting avg round 60\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 60, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.006905230078180986\n","round 60, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.004105138272279875\n","round 60, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.003477115279695551\n","round 60, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.006960386975801418\n","round 60, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.0043051624254855725\n","round 60, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.0020763479385225636\n","round 60, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.00882884830934927\n","round 60, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.0006358468937313383\n","round 60, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.009272854459205908\n","round 60, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.004827813378402167\n","round 60, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 5.8322424349005975e-05\n","round 60, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.0005599502141454389\n","round 60, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.647843582006317e-05\n","round 60, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.732383065623643e-05\n","round 60, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.0001282734099024512\n","round 60, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.00013106732250938482\n","round 60, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 8.03344767064118e-05\n","round 60, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.00032318712961486274\n","round 60, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.436495543013733e-05\n","round 60, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.00012323826488877133\n","round 60, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 8.447737753109713e-05\n","round 60, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 8.401909758917595e-05\n","round 60, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.00040315236349540234\n","round 60, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.00013799157235488177\n","round 60, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 6.99558870422834e-05\n","round 60, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.0006665660062675925\n","round 60, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.404937986254869e-05\n","round 60, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.0004846885489574301\n","round 60, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.00013966054822438836\n","round 60, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.0005090342451044957\n","round 60, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 0.00010130802968433275\n","round 60, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.0004897078295990856\n","round 60, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 6.342376702710746e-05\n","round 60, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.00048338601845898665\n","round 60, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.00016678255587164253\n","round 60, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.0001111425721579248\n","round 60, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 0.00011157245455706287\n","round 60, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.00015947540637256986\n","round 60, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.00010716415413804093\n","round 60, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.00022931552852814666\n","calc smape: 48.440831686516184%\n","MAE: 49.14845600873309\n","RMSE: 180.24980060786984\n","Average Loss:  0.004391481619431015\n","\n","starting avg round 61\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 61, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.006920811961338456\n","round 61, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.004109011913117553\n","round 61, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.00348668995346608\n","round 61, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.00690697002989639\n","round 61, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.004303853505656922\n","round 61, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.002107887464392531\n","round 61, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.00876089697703719\n","round 61, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.0006085364405277817\n","round 61, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.00926632435792791\n","round 61, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.0048584002652205536\n","round 61, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 5.7691717541853334e-05\n","round 61, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.0006379083196017227\n","round 61, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.5892690244337626e-05\n","round 61, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.602813340262011e-05\n","round 61, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.00012834259566126872\n","round 61, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.0001307070031657531\n","round 61, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 8.055719156020912e-05\n","round 61, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.0003253109927010716\n","round 61, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.338754479618468e-05\n","round 61, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.00013371958833171708\n","round 61, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 9.670860058414682e-05\n","round 61, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 8.387192323094826e-05\n","round 61, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.00040498931749815306\n","round 61, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.00014581983691641648\n","round 61, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 6.92268099027972e-05\n","round 61, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.0006631778191409205\n","round 61, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.365280248132876e-05\n","round 61, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.0004999448618556407\n","round 61, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.00013551228526661622\n","round 61, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.000505309546497301\n","round 61, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 9.647770621411057e-05\n","round 61, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.00046008517321232426\n","round 61, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 6.257160806504609e-05\n","round 61, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.000500089292472694\n","round 61, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.0001665303426047363\n","round 61, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.00011494254093642147\n","round 61, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 0.00010893033263365783\n","round 61, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.00015978746572521758\n","round 61, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.00010658684582436023\n","round 61, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.00022153973622220357\n","calc smape: 48.89564450959621%\n","MAE: 51.66470448461429\n","RMSE: 181.78752513723722\n","Average Loss:  0.00432580097809736\n","\n","starting avg round 62\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 62, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.006908985220694114\n","round 62, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.004094259771851025\n","round 62, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.0034551347364738046\n","round 62, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.006936581123487226\n","round 62, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.004279929508421837\n","round 62, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.002102866565110162\n","round 62, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.008785740197968801\n","round 62, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.0006097957289707017\n","round 62, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.009178397096028286\n","round 62, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.004821209972890625\n","round 62, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 5.9095294777348916e-05\n","round 62, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.0005003799477500642\n","round 62, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.648040349966972e-05\n","round 62, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.684440660276388e-05\n","round 62, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.00012945082709460686\n","round 62, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.00012575568355746976\n","round 62, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 8.105274222154029e-05\n","round 62, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.0003230272001143351\n","round 62, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.305283070456685e-05\n","round 62, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.00012314194683377925\n","round 62, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 8.902144156763825e-05\n","round 62, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 8.384386820084316e-05\n","round 62, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.0004031030901907278\n","round 62, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.00013830046634666357\n","round 62, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 6.831171093121414e-05\n","round 62, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.0006626949660650488\n","round 62, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.389247184707917e-05\n","round 62, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.0004824660760017909\n","round 62, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.0001417965959262801\n","round 62, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.0004937532739859308\n","round 62, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 0.00010547524482262816\n","round 62, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.00047864288249651764\n","round 62, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 6.210241923960374e-05\n","round 62, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.00047133341156170756\n","round 62, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.0001601272678815998\n","round 62, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.00010890791833974484\n","round 62, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 0.00011778500954408496\n","round 62, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.00015960438931526951\n","round 62, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.00010683519699509984\n","round 62, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.0002196552341131421\n","calc smape: 49.052491081545874%\n","MAE: 52.47540939765322\n","RMSE: 182.29060315449337\n","Average Loss:  0.004367345062945634\n","\n","starting avg round 63\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 63, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.006956511725937683\n","round 63, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.004103900989451046\n","round 63, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.0034893549953786927\n","round 63, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.006926887726876885\n","round 63, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.004350500979593825\n","round 63, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.002063023924295391\n","round 63, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.008760406361294113\n","round 63, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.0006163123853184516\n","round 63, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.009200557218199328\n","round 63, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.004845724112653571\n","round 63, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 5.9910889194725305e-05\n","round 63, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.0005875943305519675\n","round 63, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.570175821478577e-05\n","round 63, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.716120433087781e-05\n","round 63, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.00012484276239606344\n","round 63, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.00012616617991056955\n","round 63, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 8.18391998304183e-05\n","round 63, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.00032068545003147104\n","round 63, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.292817789433423e-05\n","round 63, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.00013027600230738502\n","round 63, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 9.644642591816982e-05\n","round 63, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 8.341358186498838e-05\n","round 63, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.00040856484494205294\n","round 63, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.00014853243763874552\n","round 63, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 6.832556592988632e-05\n","round 63, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.0006702021543917774\n","round 63, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.420978404873625e-05\n","round 63, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.0004951239040695198\n","round 63, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.00013811234079444797\n","round 63, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.0005056926584074971\n","round 63, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 9.949586745148865e-05\n","round 63, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.000464100610510546\n","round 63, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 6.355068636919116e-05\n","round 63, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.0004613789512534691\n","round 63, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.00016635325856993534\n","round 63, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.00010852968788250496\n","round 63, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 9.950935043434582e-05\n","round 63, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.00016003143719848045\n","round 63, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.00010661007866440706\n","round 63, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.00022161623965749402\n","calc smape: 49.01989422504339%\n","MAE: 52.84240089025985\n","RMSE: 182.6347531066128\n","Average Loss:  0.004266880992132464\n","\n","starting avg round 64\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 64, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.006776655142727707\n","round 64, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.004075221388900121\n","round 64, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.003477575020432205\n","round 64, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.006881981040351094\n","round 64, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.004277782543795183\n","round 64, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.002037327657620024\n","round 64, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.00875894380234448\n","round 64, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.0005856086852093409\n","round 64, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.009154972237800912\n","round 64, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.004814143870524799\n","round 64, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 5.8341183843036886e-05\n","round 64, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.0005605513924820117\n","round 64, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.660451993540195e-05\n","round 64, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.662530473291033e-05\n","round 64, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.00012669560673775438\n","round 64, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.00013131672313550422\n","round 64, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 8.141042667375585e-05\n","round 64, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.0003211871013739007\n","round 64, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.260729318936815e-05\n","round 64, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.00012388340059845044\n","round 64, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 8.635902288948012e-05\n","round 64, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 8.324146839930274e-05\n","round 64, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.0003996353035680451\n","round 64, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.00013348194754111577\n","round 64, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 6.856645434335665e-05\n","round 64, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.0006695703507700404\n","round 64, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.392916782260726e-05\n","round 64, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.0004707280459115283\n","round 64, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.00013855433137775563\n","round 64, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.00048320314687901235\n","round 64, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 0.00010468082517231124\n","round 64, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.0004763140251660454\n","round 64, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 6.168072856585891e-05\n","round 64, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.0004663312577447089\n","round 64, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.00016303544356333085\n","round 64, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.00011038191671884432\n","round 64, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 0.00011314879221962269\n","round 64, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.0001593280617056872\n","round 64, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.0001063239914889925\n","round 64, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.00022149761093714915\n","calc smape: 48.797322641520594%\n","MAE: 51.09537198554132\n","RMSE: 181.320059193153\n","Average Loss:  0.004305395277085657\n","\n","starting avg round 65\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 65, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.006918358857676918\n","round 65, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.004098995335100753\n","round 65, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.003448260860750451\n","round 65, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.006894268203593258\n","round 65, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.0042409961960012356\n","round 65, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.002041785965307749\n","round 65, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.008763387932309082\n","round 65, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.0005672070830249659\n","round 65, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.009113561037728295\n","round 65, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.004797421345886376\n","round 65, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 5.886945558483024e-05\n","round 65, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.000558618901257952\n","round 65, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.648686126935381e-05\n","round 65, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.596584391324409e-05\n","round 65, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.0001268392548152203\n","round 65, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.00012780545769633785\n","round 65, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 8.232139897959963e-05\n","round 65, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.00032289675565276744\n","round 65, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.590266708008647e-05\n","round 65, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.00012031288703643177\n","round 65, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 9.467775848090047e-05\n","round 65, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 8.159352267450066e-05\n","round 65, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.00039461102850119837\n","round 65, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.00013155375006590475\n","round 65, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 6.836147471744879e-05\n","round 65, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.0006458462716441967\n","round 65, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.379313368500205e-05\n","round 65, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.00048239349442675525\n","round 65, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.00014057315846522603\n","round 65, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.0004912833173875696\n","round 65, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 9.876206909861402e-05\n","round 65, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.00042692459854671536\n","round 65, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 6.138762529417362e-05\n","round 65, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.00045685313775071075\n","round 65, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.00015535151243690443\n","round 65, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.00010824524594811789\n","round 65, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 0.00010606328272290609\n","round 65, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.00015979854618497076\n","round 65, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.00011060498711770005\n","round 65, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.00022202593064085473\n","calc smape: 49.03657187817983%\n","MAE: 52.61412278045649\n","RMSE: 182.17171496441753\n","Average Loss:  0.004400700057644699\n","\n","starting avg round 66\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 66, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.00683165023968156\n","round 66, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.004080629953283017\n","round 66, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.003491967010112213\n","round 66, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.006895731402827162\n","round 66, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.004263987581777786\n","round 66, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.0020491946530195753\n","round 66, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.00878214090231008\n","round 66, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.0005729335957117395\n","round 66, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.00916117897057639\n","round 66, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.00485424474131183\n","round 66, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 5.884511271522734e-05\n","round 66, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.0005066801368229789\n","round 66, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.5685035112390846e-05\n","round 66, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.429402207240595e-05\n","round 66, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.00012801902753549425\n","round 66, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.00012587854147178793\n","round 66, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 8.07491040372302e-05\n","round 66, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.0003228648967582227\n","round 66, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.391922178890257e-05\n","round 66, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.00012367896127735937\n","round 66, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 8.87243555983527e-05\n","round 66, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 8.252120558774384e-05\n","round 66, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.0003942496509158185\n","round 66, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.00013372244166021116\n","round 66, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 6.80068454528282e-05\n","round 66, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.0006488386799381778\n","round 66, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.367739822670565e-05\n","round 66, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.0005007364462861525\n","round 66, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.00013524888787027782\n","round 66, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.0004857548553575594\n","round 66, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 9.221160657294347e-05\n","round 66, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.0004188710554444695\n","round 66, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 6.0703607928758174e-05\n","round 66, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.00045840664669023155\n","round 66, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.0001640959764464307\n","round 66, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.00011104186127600507\n","round 66, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 0.00010746382688304427\n","round 66, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.00015907571340869497\n","round 66, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.00010653136476961392\n","round 66, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.00022000051784811214\n","calc smape: 49.18032218770213%\n","MAE: 53.4795271662232\n","RMSE: 182.69231299881886\n","Average Loss:  0.0042959644875478825\n","\n","starting avg round 67\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 67, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.006881317946993347\n","round 67, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.004055603823092366\n","round 67, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.003454929741565138\n","round 67, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.006903612836530163\n","round 67, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.004322461501163032\n","round 67, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.0020305681121369286\n","round 67, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.00877603465258809\n","round 67, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.0005486852179663922\n","round 67, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.009130258861530039\n","round 67, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.004838933952019684\n","round 67, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 5.7612822535123654e-05\n","round 67, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.0005016032134465473\n","round 67, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.611255841626058e-05\n","round 67, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.691239576550808e-05\n","round 67, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.00012398183790722852\n","round 67, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.00012625650514256189\n","round 67, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 8.052559207629071e-05\n","round 67, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.00032310263323283414\n","round 67, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.630860001509841e-05\n","round 67, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.0001306526130357659\n","round 67, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 0.00010016704382158942\n","round 67, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 8.25955778034106e-05\n","round 67, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.00039694126774390614\n","round 67, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.0001277866842477644\n","round 67, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 7.05366105689466e-05\n","round 67, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.0006732681951169591\n","round 67, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.401970064270504e-05\n","round 67, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.0004748656652476973\n","round 67, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.0001357965714175537\n","round 67, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.0004768002316788106\n","round 67, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 9.694416420253607e-05\n","round 67, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.0004319801597115917\n","round 67, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 6.265238549271348e-05\n","round 67, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.0004952340303654118\n","round 67, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.00015891697086090062\n","round 67, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.00011072853879211058\n","round 67, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 0.00011860314282330363\n","round 67, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.00015911920954234996\n","round 67, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.00011211862109424449\n","round 67, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.0002197534184873533\n","calc smape: 49.07689734323863%\n","MAE: 52.5031385187826\n","RMSE: 181.9026705696729\n","Average Loss:  0.00444801669776846\n","\n","starting avg round 68\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 68, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.006811774028132535\n","round 68, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.004053235241112167\n","round 68, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.003449709782476671\n","round 68, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.006831005041021854\n","round 68, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.004237883034095701\n","round 68, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.0020447444403544064\n","round 68, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.00873121990090502\n","round 68, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.0005944756893378715\n","round 68, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.0091633902796145\n","round 68, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.004840024593119908\n","round 68, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 5.8146361681627405e-05\n","round 68, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.0005641079395510523\n","round 68, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.539621768831888e-05\n","round 68, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.588779543051974e-05\n","round 68, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.00012375244497249055\n","round 68, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.00012332101383906644\n","round 68, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 8.000361588398972e-05\n","round 68, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.0003194965854700885\n","round 68, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.263298375117301e-05\n","round 68, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.0001227413155220347\n","round 68, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 9.341661154849135e-05\n","round 68, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 8.270224692420344e-05\n","round 68, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.00039321845750756815\n","round 68, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.00013641822142419966\n","round 68, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 7.01586626356792e-05\n","round 68, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.0006189866185845204\n","round 68, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.344330250637346e-05\n","round 68, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.0004936796828717757\n","round 68, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.00013261127125068536\n","round 68, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.00047699796830004605\n","round 68, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 9.808546870512406e-05\n","round 68, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.00043853155979637194\n","round 68, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 6.080646519584271e-05\n","round 68, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.0004547906974039506\n","round 68, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.00015544598316604864\n","round 68, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.00011192474994459187\n","round 68, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 0.00011092853734291045\n","round 68, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.00015926849911217152\n","round 68, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.00010918089739991249\n","round 68, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.00021937441628054973\n","calc smape: 49.13882152781849%\n","MAE: 53.11047236095393\n","RMSE: 182.27401313991567\n","Average Loss:  0.004349584841139356\n","\n","starting avg round 69\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 69, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.006869515146328401\n","round 69, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.004065101005835459\n","round 69, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.003491759716000939\n","round 69, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.006949406557915999\n","round 69, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.004205358156468718\n","round 69, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.002025676662534741\n","round 69, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.008742327593998714\n","round 69, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.0005468072339291604\n","round 69, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.009122593935379496\n","round 69, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.004821576735204352\n","round 69, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 5.760791005658658e-05\n","round 69, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.0005072836257958053\n","round 69, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.616044106699388e-05\n","round 69, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.61196986007105e-05\n","round 69, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.00012490310763900602\n","round 69, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.0001243518568035792\n","round 69, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 7.97247051065954e-05\n","round 69, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.00031908581856276383\n","round 69, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.165253747564099e-05\n","round 69, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.00012238560105158413\n","round 69, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 8.886564801611841e-05\n","round 69, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 8.250689942418502e-05\n","round 69, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.0003907088038041756\n","round 69, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.00013963880356219045\n","round 69, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 7.046050696755759e-05\n","round 69, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.0006281039828276595\n","round 69, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.862460870950469e-05\n","round 69, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.000486509598756259\n","round 69, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.00013579381343983444\n","round 69, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.00046850214597985275\n","round 69, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 9.755386684316494e-05\n","round 69, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.0004235549651119593\n","round 69, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 6.106383147295803e-05\n","round 69, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.000417686990268911\n","round 69, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.00015707122801294254\n","round 69, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.00010943860784859031\n","round 69, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 0.00013534370218134685\n","round 69, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.00015851529943609178\n","round 69, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.00010628483673153149\n","round 69, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.00021965489159575313\n","calc smape: 49.26224331827327%\n","MAE: 53.77413923035265\n","RMSE: 182.7182829751663\n","Average Loss:  0.0044423432797900935\n","\n","starting avg round 70\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 70, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.006734970100556633\n","round 70, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.00404773440511365\n","round 70, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.003492370684398338\n","round 70, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.006922247279102781\n","round 70, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.004248046278787245\n","round 70, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.0020562096906360234\n","round 70, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.008722769387532029\n","round 70, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.0005609802439201822\n","round 70, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.009187821847652752\n","round 70, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.004843503461285893\n","round 70, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 5.751189803711234e-05\n","round 70, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.0005081417470397095\n","round 70, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.569118895655525e-05\n","round 70, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.598686436592419e-05\n","round 70, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.00012123660609067547\n","round 70, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.0001225393293842509\n","round 70, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 8.052206242479899e-05\n","round 70, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.0003204337050647155\n","round 70, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.37658242768131e-05\n","round 70, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.0001209314120355235\n","round 70, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 8.590605486753182e-05\n","round 70, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 8.111605453367784e-05\n","round 70, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.00039017692467626015\n","round 70, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.0001294178649686728\n","round 70, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 6.972146701806585e-05\n","round 70, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.0006601487738017958\n","round 70, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.396354932901106e-05\n","round 70, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.00047400229232152924\n","round 70, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.00013449058860715013\n","round 70, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.00047408575145319845\n","round 70, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 0.00010004086152548555\n","round 70, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.0004307500561740848\n","round 70, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 6.01859934964263e-05\n","round 70, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.0004385486242556778\n","round 70, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.00015658649057773543\n","round 70, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.00010924680041820725\n","round 70, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 0.00010688362613109348\n","round 70, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.0001592888819652457\n","round 70, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.00010767544711564335\n","round 70, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.000218450886020744\n","calc smape: 49.069362756224734%\n","MAE: 52.68190144737961\n","RMSE: 181.89588894726677\n","Average Loss:  0.004297466246546162\n","\n","starting avg round 71\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 71, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.0068033407026502676\n","round 71, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.004030061565572396\n","round 71, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.003471874540472138\n","round 71, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.006898905591307475\n","round 71, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.004274356561446828\n","round 71, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.0020304800231575166\n","round 71, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.008711040269450418\n","round 71, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.0005445016156175242\n","round 71, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.00920210013698254\n","round 71, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.004816830495006537\n","round 71, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 5.839048299507835e-05\n","round 71, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.0005199140900263697\n","round 71, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.543765754760897e-05\n","round 71, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.648497137324738e-05\n","round 71, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.00012646753167347118\n","round 71, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.00012304279530082698\n","round 71, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 8.052958316641577e-05\n","round 71, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.0003275989789844144\n","round 71, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.308670354357672e-05\n","round 71, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.00013332574922385117\n","round 71, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 8.750353032788944e-05\n","round 71, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 8.117039688344946e-05\n","round 71, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.0003867605955747421\n","round 71, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.00013395051418488686\n","round 71, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 0.00010283989783894349\n","round 71, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.0006050847363699829\n","round 71, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.392500500851384e-05\n","round 71, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.00045791854219195174\n","round 71, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.00013671200226131726\n","round 71, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.0004695862556088417\n","round 71, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 9.913890020080935e-05\n","round 71, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.0004652880111929595\n","round 71, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 5.9321012624228116e-05\n","round 71, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.00043759098558179447\n","round 71, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.00015857182391901655\n","round 71, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.00010991781813832596\n","round 71, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 0.00010504867330090357\n","round 71, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.00015911847370536533\n","round 71, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.00010543009312237294\n","round 71, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.00021870382272060887\n","calc smape: 49.24895387254501%\n","MAE: 54.372849698934516\n","RMSE: 183.1579579677913\n","Average Loss:  0.004210595314823113\n","\n","starting avg round 72\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 72, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.006827027087898129\n","round 72, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.004019087874829504\n","round 72, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.0034346172012322184\n","round 72, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.006818654963613623\n","round 72, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.00418270006360087\n","round 72, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.0020446124544832855\n","round 72, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.00867561431368813\n","round 72, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.000552014021195646\n","round 72, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.00912261993757316\n","round 72, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.004802827390709093\n","round 72, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 5.720198762239968e-05\n","round 72, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.000686087462132231\n","round 72, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.620167834445965e-05\n","round 72, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.761625642745328e-05\n","round 72, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.00012357828732260882\n","round 72, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.00012339539519449057\n","round 72, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 8.07407051784789e-05\n","round 72, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.0003210655783236275\n","round 72, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.29135045534427e-05\n","round 72, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.00011638924029609502\n","round 72, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 8.448075686828817e-05\n","round 72, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 8.297156271262132e-05\n","round 72, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.0003862920851003894\n","round 72, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.000136802251566743\n","round 72, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 7.109405041611743e-05\n","round 72, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.0006505481703373205\n","round 72, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.362426767379604e-05\n","round 72, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.00045599315256237904\n","round 72, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.0001376489270634401\n","round 72, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.000456117269225485\n","round 72, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 9.980844255811201e-05\n","round 72, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.000446189313931557\n","round 72, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 6.070214305558303e-05\n","round 72, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.0004217050744565702\n","round 72, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.00015597396683883095\n","round 72, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.00010612718200978376\n","round 72, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 0.00010354292755567127\n","round 72, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.00015968949943906513\n","round 72, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.00010546141809889512\n","round 72, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.00021815870342868065\n","calc smape: 49.2887842516296%\n","MAE: 54.02645627902765\n","RMSE: 182.69981598077948\n","Average Loss:  0.004270652031608058\n","\n","starting avg round 73\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 73, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.006753752714887794\n","round 73, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.0039973766168779025\n","round 73, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.0034237141205397032\n","round 73, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.006785517184263362\n","round 73, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.004216505156364292\n","round 73, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.001994407184871047\n","round 73, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.008698610713638899\n","round 73, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.0005115345294533262\n","round 73, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.009114411576384943\n","round 73, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.0048126934478724655\n","round 73, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 5.7568720124188316e-05\n","round 73, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.00048573188463966034\n","round 73, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.6487882749650975e-05\n","round 73, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.758396691315284e-05\n","round 73, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.00012061051994452199\n","round 73, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.00012416414986254106\n","round 73, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 7.941426997604137e-05\n","round 73, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.0003249641082716566\n","round 73, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.403704837853053e-05\n","round 73, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.00012368845370604374\n","round 73, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 8.511825125927836e-05\n","round 73, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 8.342115089693502e-05\n","round 73, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.00038806063210878553\n","round 73, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.0001240153738016098\n","round 73, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 7.155161019665811e-05\n","round 73, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.000613455560077065\n","round 73, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.366547153139177e-05\n","round 73, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.00045197646613814873\n","round 73, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.00013669636570869313\n","round 73, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.00045297647349278644\n","round 73, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 9.661026599262967e-05\n","round 73, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.00041045417934323534\n","round 73, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 5.887170408820047e-05\n","round 73, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.00041679618334455887\n","round 73, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.0001537662120004565\n","round 73, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.00011080715187615301\n","round 73, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 0.00010910320729960531\n","round 73, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.00015915797249397412\n","round 73, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.00010484628097839485\n","round 73, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.00021744293007099327\n","calc smape: 49.02478396174976%\n","MAE: 53.49577525860413\n","RMSE: 182.5813460557032\n","Average Loss:  0.004046324096408397\n","\n","starting avg round 74\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 74, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.006723347610594437\n","round 74, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.00396127430472656\n","round 74, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.003424899195254381\n","round 74, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.006778015904793783\n","round 74, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.004138632074630418\n","round 74, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.0020143624465812798\n","round 74, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.008669465015243207\n","round 74, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.0004834999768458407\n","round 74, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.00905343655696405\n","round 74, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.004739089149682384\n","round 74, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 5.7390425271560986e-05\n","round 74, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.00048277572152853414\n","round 74, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.610535428842662e-05\n","round 74, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.805807027645121e-05\n","round 74, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.00012132098119629385\n","round 74, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.00012283222746337482\n","round 74, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 8.217508034899115e-05\n","round 74, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.0003221395914599931\n","round 74, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.397025296006435e-05\n","round 74, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.00012073097280205858\n","round 74, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 8.303009626940496e-05\n","round 74, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 8.159342907095958e-05\n","round 74, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.0003875794877136026\n","round 74, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.00013862395733862546\n","round 74, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 7.007651641239524e-05\n","round 74, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.0005839102377649399\n","round 74, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.39132128087892e-05\n","round 74, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.00046595368673609184\n","round 74, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.00013435069474456083\n","round 74, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.00044412260467652226\n","round 74, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 9.837316643565176e-05\n","round 74, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.00038942360723532546\n","round 74, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 5.7758932436107504e-05\n","round 74, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.00040702004662307456\n","round 74, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.00016493890431336564\n","round 74, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.00010349032569527999\n","round 74, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 9.995471050063184e-05\n","round 74, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.00015896812182428167\n","round 74, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.00010548974608826499\n","round 74, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.00021734213774598848\n","calc smape: 49.51231481375561%\n","MAE: 56.32110761085282\n","RMSE: 184.52259828629263\n","Average Loss:  0.004188367642641659\n","\n","starting avg round 75\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 75, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.006771239834571523\n","round 75, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.003976746383289408\n","round 75, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.0034448092711889854\n","round 75, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.00675290621750589\n","round 75, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.00417537343206017\n","round 75, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.001993685102206655\n","round 75, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.008705937561379478\n","round 75, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.0004952416898699344\n","round 75, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.00907005708930748\n","round 75, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.004770180031690482\n","round 75, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 5.924981418998372e-05\n","round 75, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.0004600265770672456\n","round 75, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.6320358973974044e-05\n","round 75, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.777974495378918e-05\n","round 75, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.00011934144842800582\n","round 75, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.00012382169768849444\n","round 75, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 8.054031150095398e-05\n","round 75, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.00031775681750952404\n","round 75, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.981798351483512e-05\n","round 75, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.00011816425348700122\n","round 75, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 8.701589060576355e-05\n","round 75, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 8.121457806902816e-05\n","round 75, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.00038857817266294394\n","round 75, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.00013022598563696062\n","round 75, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 6.95020500123584e-05\n","round 75, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.0005775791399043682\n","round 75, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.351675689789512e-05\n","round 75, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.0004470207529396117\n","round 75, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.00013568015661543801\n","round 75, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.00045809451538454074\n","round 75, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 9.957639914708642e-05\n","round 75, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.000387193612498647\n","round 75, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 6.159832773278141e-05\n","round 75, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.00044536845078775014\n","round 75, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.00015899442255269084\n","round 75, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.00010352559749143047\n","round 75, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 0.00011061688675389241\n","round 75, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.00015992981754933222\n","round 75, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.00010434193179915183\n","round 75, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.00021748051996702867\n","calc smape: 49.21317976071353%\n","MAE: 54.203467333191995\n","RMSE: 182.86076472879233\n","Average Loss:  0.004246077954794446\n","\n","starting avg round 76\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 76, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.006728852001417959\n","round 76, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.004006498672034858\n","round 76, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.0033829796635213177\n","round 76, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.0067518959320815525\n","round 76, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.004168390512599477\n","round 76, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.0019839335810892017\n","round 76, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.00870924460468814\n","round 76, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.0005440597090325483\n","round 76, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.00904844609820949\n","round 76, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.004788023182689877\n","round 76, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 5.779418943347991e-05\n","round 76, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.0004985120961334489\n","round 76, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.639401230731112e-05\n","round 76, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.94322217123928e-05\n","round 76, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.00012063377303345787\n","round 76, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.00012207007927551266\n","round 76, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 8.006398934412573e-05\n","round 76, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.0003275527093385541\n","round 76, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.790569562742997e-05\n","round 76, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.00011913503699036348\n","round 76, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 8.738289255104192e-05\n","round 76, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 7.992380372095134e-05\n","round 76, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.00037663933146957006\n","round 76, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.00013673844984753356\n","round 76, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 7.033819192007027e-05\n","round 76, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.000592385881515968\n","round 76, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.440713268927668e-05\n","round 76, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.00045708069644336176\n","round 76, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.00013022844677834658\n","round 76, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.0004462510273047622\n","round 76, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 8.93491920318671e-05\n","round 76, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.0004133389317887902\n","round 76, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 5.826046980165041e-05\n","round 76, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.0004130306271170931\n","round 76, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.0001656922020742968\n","round 76, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.00010742252353728483\n","round 76, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 0.00011989297205770657\n","round 76, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.00015864684345152065\n","round 76, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.0001043477686582466\n","round 76, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.00021867687615263593\n","calc smape: 49.10485430734249%\n","MAE: 54.68164069167874\n","RMSE: 183.36724172733332\n","Average Loss:  0.003969553986791866\n","\n","starting avg round 77\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 77, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.0067206841693925\n","round 77, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.0039512960938736805\n","round 77, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.0033963181569041426\n","round 77, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.006737754397493387\n","round 77, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.004143202989195873\n","round 77, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.0019176792182926349\n","round 77, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.008647251425177922\n","round 77, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.0004505411661739344\n","round 77, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.00908014106763793\n","round 77, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.004719205425187415\n","round 77, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 5.767882737679677e-05\n","round 77, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.000530452159572243\n","round 77, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.680965800421939e-05\n","round 77, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.885225366927833e-05\n","round 77, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.00011845833694223984\n","round 77, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.00011933336719900061\n","round 77, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 7.999187804281455e-05\n","round 77, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.0003117374964941436\n","round 77, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.75059504883445e-05\n","round 77, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.00011816904360070374\n","round 77, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 8.296495713417633e-05\n","round 77, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 8.002940946260587e-05\n","round 77, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.0003724022564191338\n","round 77, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.00013343192740324284\n","round 77, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 7.09069524183243e-05\n","round 77, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.0005994090850955607\n","round 77, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.347130583403018e-05\n","round 77, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.0004251516056683613\n","round 77, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.00013538505079070868\n","round 77, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.0004307063505361189\n","round 77, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 9.497351961077325e-05\n","round 77, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.0004191545472817129\n","round 77, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 5.781901842689356e-05\n","round 77, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.0004092011279551248\n","round 77, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.00015325281168949393\n","round 77, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.00010159208185151721\n","round 77, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 0.0001097328708803096\n","round 77, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.00015828709855376694\n","round 77, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.00010494910034813747\n","round 77, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.00021648876472008172\n","calc smape: 49.03757635124479%\n","MAE: 53.34866391763519\n","RMSE: 182.30109346047897\n","Average Loss:  0.004167668468632537\n","\n","starting avg round 78\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 78, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.006732395268045367\n","round 78, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.0039687450334895385\n","round 78, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.003362007405874984\n","round 78, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.006699398700480483\n","round 78, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.004166491051104717\n","round 78, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.0019320349612306541\n","round 78, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.008698516799735705\n","round 78, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.0005685027734736131\n","round 78, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.009059745959738002\n","round 78, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.004757057297475902\n","round 78, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 5.713229137323983e-05\n","round 78, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.0004546593037438081\n","round 78, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.608673854785852e-05\n","round 78, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.822012303547255e-05\n","round 78, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.00011952862053021815\n","round 78, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.00011967004378529315\n","round 78, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 7.832022197362676e-05\n","round 78, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.0003180691246060714\n","round 78, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.490992738392376e-05\n","round 78, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.00010885906242817456\n","round 78, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 8.53231426601399e-05\n","round 78, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 7.916492453742566e-05\n","round 78, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.0003788513199002149\n","round 78, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.00012819271302890093\n","round 78, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 6.805944631845965e-05\n","round 78, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.0005627297928835365\n","round 78, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.353287478028895e-05\n","round 78, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.0004444782831082453\n","round 78, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.00012989293730113007\n","round 78, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.00044263394192967104\n","round 78, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 9.017372573388064e-05\n","round 78, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.00037632558788962863\n","round 78, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 6.1521102174262e-05\n","round 78, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.0003994444983358595\n","round 78, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.0001573585941149044\n","round 78, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.00010909208400075188\n","round 78, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 9.722368320451225e-05\n","round 78, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.00015943628981626972\n","round 78, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.00010343529880561548\n","round 78, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.000215207253926632\n","calc smape: 49.47234387713089%\n","MAE: 55.80567245174686\n","RMSE: 183.773773820035\n","Average Loss:  0.004090141546092204\n","\n","starting avg round 79\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 79, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.0066946653948564624\n","round 79, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.0039759785078266364\n","round 79, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.003422842922321122\n","round 79, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.006681438593659548\n","round 79, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.004159682771257523\n","round 79, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.0019227255522439785\n","round 79, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.00865843389016975\n","round 79, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.0005003534444248155\n","round 79, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.009038838258545318\n","round 79, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.0047340050348014156\n","round 79, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 5.983035665518731e-05\n","round 79, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.00045917811387750717\n","round 79, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.6203862991335746e-05\n","round 79, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.799217738530776e-05\n","round 79, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.00012140005711208452\n","round 79, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.00013100118222350178\n","round 79, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 7.797341985289156e-05\n","round 79, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.00031302186146356023\n","round 79, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.61273126287259e-05\n","round 79, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.00011143132678625989\n","round 79, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 8.468657143469371e-05\n","round 79, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 8.082176392979985e-05\n","round 79, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.00038001602687082973\n","round 79, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.00013498914838042507\n","round 79, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 7.68864102594437e-05\n","round 79, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.0005555467354757379\n","round 79, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.41206341599952e-05\n","round 79, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.00042805223659213103\n","round 79, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.00013062934996404301\n","round 79, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.0004306880022600773\n","round 79, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 9.293612954154793e-05\n","round 79, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.0003977638971264241\n","round 79, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 6.348350271829466e-05\n","round 79, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.00040239700501842885\n","round 79, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.00014889252281591323\n","round 79, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.00011174824391803536\n","round 79, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 0.00011532527423696592\n","round 79, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.00015868010948151835\n","round 79, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.00010268299439741424\n","round 79, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.00021855138333261556\n","calc smape: 49.418843607954315%\n","MAE: 55.79038645984512\n","RMSE: 183.81041985067176\n","Average Loss:  0.004060856535421757\n","\n","starting avg round 80\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 80, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.006731784262228754\n","round 80, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.003959706285968424\n","round 80, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.0033383152913302183\n","round 80, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.006676060006222022\n","round 80, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.004106170738980706\n","round 80, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.0019165605314940748\n","round 80, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.008682625401499016\n","round 80, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.0005124149224034877\n","round 80, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.009021201270765491\n","round 80, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.004771389615988093\n","round 80, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 5.729084827056464e-05\n","round 80, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.0005332929842032689\n","round 80, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.638090679317688e-05\n","round 80, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.832739626272605e-05\n","round 80, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.00011973566497376682\n","round 80, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.00012672628380577014\n","round 80, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 8.020660938460163e-05\n","round 80, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.0003141317823561125\n","round 80, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.325214181542053e-05\n","round 80, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.00011934142089233186\n","round 80, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 8.447884970053111e-05\n","round 80, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 8.281891141450614e-05\n","round 80, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.0003831515241472515\n","round 80, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.00012566404008599162\n","round 80, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 7.073541976053223e-05\n","round 80, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.000571356410156503\n","round 80, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.31992463654894e-05\n","round 80, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.00041105040976877457\n","round 80, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.00013122684790037707\n","round 80, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.0004423299399474802\n","round 80, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 9.84561023480118e-05\n","round 80, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.0003817504415824909\n","round 80, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 5.849178569405921e-05\n","round 80, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.00040432570884669475\n","round 80, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.00015330048989069055\n","round 80, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.00011007602954902853\n","round 80, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 0.00011858461316803315\n","round 80, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.00015830841549651045\n","round 80, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.00010583711409876908\n","round 80, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.00021860780455224606\n","calc smape: 49.40204525674759%\n","MAE: 55.531971452890275\n","RMSE: 183.55848668227299\n","Average Loss:  0.0040920357028298715\n","\n","starting avg round 81\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 81, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.006678067330670143\n","round 81, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.0039529882778879255\n","round 81, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.003342168384863596\n","round 81, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.006659392857857584\n","round 81, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.00410530376081754\n","round 81, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.0019133755039157613\n","round 81, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.008667169870542628\n","round 81, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.0004741966224953234\n","round 81, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.009074407588091811\n","round 81, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.00470989797031507\n","round 81, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 5.832901824760483e-05\n","round 81, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.00047979620415260026\n","round 81, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.5794235733507905e-05\n","round 81, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.772550410274043e-05\n","round 81, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.00012104119377909227\n","round 81, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.00011798661576481857\n","round 81, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 7.757777221481127e-05\n","round 81, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.0003111015719613616\n","round 81, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.389898280330402e-05\n","round 81, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.00011408711887790041\n","round 81, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 8.324965325203137e-05\n","round 81, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 7.99993849423944e-05\n","round 81, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.00036444067986199775\n","round 81, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.00012669630534998893\n","round 81, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 7.087864513875632e-05\n","round 81, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.0005865994909462252\n","round 81, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.386800122624794e-05\n","round 81, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.0004006395127882052\n","round 81, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.00012794177447566262\n","round 81, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.00043423576374022676\n","round 81, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 0.00010186140681461049\n","round 81, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.00038794069145556655\n","round 81, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 5.9778467634227385e-05\n","round 81, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.0004120212067521476\n","round 81, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.00015330363481374273\n","round 81, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.00011050977088546329\n","round 81, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 0.00011668356705740734\n","round 81, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.00015964569376832649\n","round 81, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.00010428977479595805\n","round 81, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.00021626537864836718\n","calc smape: 49.48479910641694%\n","MAE: 56.82103347015631\n","RMSE: 184.6822074666922\n","Average Loss:  0.0039020094637086584\n","\n","starting avg round 82\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 82, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.006703823863063004\n","round 82, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.003948541595101622\n","round 82, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.003338120108570107\n","round 82, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.00669893331360072\n","round 82, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.004093242343515158\n","round 82, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.0019015393793649438\n","round 82, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.008657269520751602\n","round 82, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.0004586938499154972\n","round 82, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.00900245283264667\n","round 82, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.004675254832753645\n","round 82, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 5.8173157241402475e-05\n","round 82, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.00042889377073151996\n","round 82, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.649607192115061e-05\n","round 82, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.934797495831194e-05\n","round 82, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.00011849058782226402\n","round 82, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.00012202492032591698\n","round 82, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 7.850670080447996e-05\n","round 82, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.00032213624237391\n","round 82, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.580738437112554e-05\n","round 82, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.00011237727372710129\n","round 82, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 8.276358511644892e-05\n","round 82, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 8.108282486732192e-05\n","round 82, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.00036475267370406067\n","round 82, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.0001334044124275481\n","round 82, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 7.125997224680499e-05\n","round 82, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.0005235226329075107\n","round 82, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.38872200633094e-05\n","round 82, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.00039440473327496354\n","round 82, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.0001323377179817596\n","round 82, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.0004146166146321256\n","round 82, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 9.6682456322534e-05\n","round 82, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.000360090614256998\n","round 82, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 5.8925462147791616e-05\n","round 82, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.0003853712649808067\n","round 82, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.00015351235737983058\n","round 82, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.00011340470924941269\n","round 82, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 0.00010551550622039936\n","round 82, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.0001602538813268387\n","round 82, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.00010309409560283745\n","round 82, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.0002161048791246382\n","calc smape: 49.87052453043733%\n","MAE: 58.663995812346876\n","RMSE: 185.9673491368259\n","Average Loss:  0.004049606229659808\n","\n","starting avg round 83\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 83, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.006671067019591908\n","round 83, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.003942848848445075\n","round 83, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.003330525937989088\n","round 83, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.006682993702790032\n","round 83, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.004124190221773461\n","round 83, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.0018897835252573711\n","round 83, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.008631163800600916\n","round 83, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.00047002873231706733\n","round 83, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.0089957487070933\n","round 83, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.004711833828228658\n","round 83, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 6.0442207036844166e-05\n","round 83, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.0004396093666270774\n","round 83, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.6345046168231176e-05\n","round 83, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.8898751212364e-05\n","round 83, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.00012199487392300162\n","round 83, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.00012187264357115576\n","round 83, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 7.843181937719884e-05\n","round 83, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.0003100022303814596\n","round 83, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.371974869866658e-05\n","round 83, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.00010922721332917718\n","round 83, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 8.805304840718365e-05\n","round 83, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 8.383132473103284e-05\n","round 83, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.0003775496032696019\n","round 83, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.00013485108596406853\n","round 83, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 7.042913184055318e-05\n","round 83, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.0005761707086224176\n","round 83, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.452173036564092e-05\n","round 83, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.00039654386715223415\n","round 83, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.00012910927872716066\n","round 83, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.0004863323935881323\n","round 83, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 9.571384579690598e-05\n","round 83, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.00037691116631322064\n","round 83, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 5.994555896953507e-05\n","round 83, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.0003877886902046158\n","round 83, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.00015395716106273282\n","round 83, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.00011295456611800809\n","round 83, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 0.00011098294174059577\n","round 83, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.00015909984827061944\n","round 83, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.00010283908602559678\n","round 83, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.000215305047714975\n","calc smape: 49.281127973315876%\n","MAE: 54.99829916858432\n","RMSE: 183.10582143021836\n","Average Loss:  0.004019913267572466\n","\n","starting avg round 84\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 84, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.006644101114943626\n","round 84, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.003953212456378553\n","round 84, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.0033531376435088794\n","round 84, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.0066770999941841835\n","round 84, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.004114386538276449\n","round 84, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.0019062397976605488\n","round 84, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.008614644549587474\n","round 84, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.00048272884214384265\n","round 84, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.00898525580331417\n","round 84, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.00469123153015971\n","round 84, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 5.802252877319088e-05\n","round 84, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.0004556479398161174\n","round 84, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.6034363078563607e-05\n","round 84, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.85928509198389e-05\n","round 84, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.00011741665330360032\n","round 84, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.0001233071510325447\n","round 84, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 7.771979244353132e-05\n","round 84, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.0003249749645130412\n","round 84, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.164862002210481e-05\n","round 84, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.00012219696156989815\n","round 84, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 8.46685344981779e-05\n","round 84, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 8.058159867439164e-05\n","round 84, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.0003728095308750718\n","round 84, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.00012825332063519973\n","round 84, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 6.94498534090014e-05\n","round 84, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.0005235281953771067\n","round 84, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.368424483785669e-05\n","round 84, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.00040472564510959523\n","round 84, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.00012915532858772037\n","round 84, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.00042243255237346087\n","round 84, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 9.71406044365202e-05\n","round 84, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.00039307996641062867\n","round 84, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 5.9351184473501106e-05\n","round 84, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.0004001408643879196\n","round 84, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.0001504266450556965\n","round 84, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.00010999685706078055\n","round 84, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 0.00010798416259051789\n","round 84, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.00015880372393439754\n","round 84, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.00010426519856907732\n","round 84, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.00021766954030142554\n","calc smape: 49.65920050202035%\n","MAE: 57.11212662003216\n","RMSE: 184.65817999127663\n","Average Loss:  0.004080878168446316\n","\n","starting avg round 85\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 85, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.006693470399893289\n","round 85, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.003925856452302209\n","round 85, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.0033511713222001815\n","round 85, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.006646529047949505\n","round 85, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.0041299961615420345\n","round 85, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.0019022422347916288\n","round 85, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.008642116087555354\n","round 85, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.000452582524823291\n","round 85, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.009009141998831183\n","round 85, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.0047047207107035706\n","round 85, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 5.703313095182239e-05\n","round 85, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.0004606020372323525\n","round 85, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.666161381042651e-05\n","round 85, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.838763878810693e-05\n","round 85, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.00011531228023563419\n","round 85, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.00012008779216492776\n","round 85, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 7.705208106147309e-05\n","round 85, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.00034256276563527624\n","round 85, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.463144842162104e-05\n","round 85, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.00010938144219250847\n","round 85, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 8.055937652378425e-05\n","round 85, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 8.037114085833641e-05\n","round 85, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.0003830762525467436\n","round 85, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.00013281238212974652\n","round 85, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 6.909394239836988e-05\n","round 85, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.000536782723689352\n","round 85, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.345278520874282e-05\n","round 85, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.0004004431861436127\n","round 85, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.00012619115139906565\n","round 85, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.000430944002281259\n","round 85, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 9.749960333595353e-05\n","round 85, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.0003801508527041214\n","round 85, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 5.97860054004481e-05\n","round 85, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.0003849227853476934\n","round 85, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.00014904492032233714\n","round 85, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.0001104108049665748\n","round 85, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 0.00010675004025577956\n","round 85, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.00015916779395136577\n","round 85, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.00010389989415250092\n","round 85, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.00021636394198712542\n","calc smape: 49.708557452640704%\n","MAE: 57.86812158918737\n","RMSE: 185.28132846371759\n","Average Loss:  0.0038010287127736445\n","\n","starting avg round 86\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 86, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.0066717489057087475\n","round 86, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.0039044360372437444\n","round 86, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.003319909767014906\n","round 86, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.006633200715961202\n","round 86, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.004067019692489079\n","round 86, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.0018721506473541789\n","round 86, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.008644270053732073\n","round 86, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.00040222271296183214\n","round 86, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.00899620463938585\n","round 86, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.004675327712902801\n","round 86, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 5.672097438284915e-05\n","round 86, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.0004362911952609595\n","round 86, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.649121068415038e-05\n","round 86, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.87829561334417e-05\n","round 86, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.00011961052106286204\n","round 86, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.00012433423553862407\n","round 86, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 7.819770023940822e-05\n","round 86, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.000317622624950011\n","round 86, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.762008903635433e-05\n","round 86, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.00011819222975516041\n","round 86, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 8.608663691640165e-05\n","round 86, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 7.715306225112396e-05\n","round 86, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.00035797316390276775\n","round 86, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.00013102310148432092\n","round 86, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 7.1444735859976e-05\n","round 86, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.0005059368052440863\n","round 86, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.347200782589165e-05\n","round 86, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.0003770919889315598\n","round 86, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.00012658690411626591\n","round 86, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.0004511867585149178\n","round 86, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 9.13030837637052e-05\n","round 86, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.00037466563974573685\n","round 86, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 5.749737810236053e-05\n","round 86, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.00039626073469532607\n","round 86, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.00015692950367045857\n","round 86, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.00010915812198878225\n","round 86, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 0.00011050968413428564\n","round 86, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.00015915936904453904\n","round 86, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.00010120989065853789\n","round 86, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.00021335111467090395\n","calc smape: 49.22319361393664%\n","MAE: 55.127502052010854\n","RMSE: 183.118704464227\n","Average Loss:  0.003942634197823326\n","\n","starting avg round 87\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 87, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.006661953146768998\n","round 87, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.00392591702984646\n","round 87, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.0033386007458570286\n","round 87, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.006609104282688349\n","round 87, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.004083350267527357\n","round 87, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.0018938179127871988\n","round 87, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.008596816233226232\n","round 87, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.0004418757883156235\n","round 87, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.008956749699011977\n","round 87, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.004678910606474214\n","round 87, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 5.862816377967565e-05\n","round 87, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.0004691217904369945\n","round 87, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.6049857709411815e-05\n","round 87, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.939907844242304e-05\n","round 87, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.0001168365182088059\n","round 87, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.00011860009457872625\n","round 87, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 7.729250653807996e-05\n","round 87, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.0003243233298441985\n","round 87, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.261158598811953e-05\n","round 87, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.0001125930457744419\n","round 87, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 8.178951601475351e-05\n","round 87, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 8.088681055679363e-05\n","round 87, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.00036768034143668573\n","round 87, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.00013225579898192206\n","round 87, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 6.929061102921098e-05\n","round 87, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.0005379271629603218\n","round 87, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.32744160254463e-05\n","round 87, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.0003820094586574538\n","round 87, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.00012642062373353316\n","round 87, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.0004062827195282029\n","round 87, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 9.412099867794104e-05\n","round 87, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.00034673929440032225\n","round 87, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 5.894695114453238e-05\n","round 87, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.0003786831881110889\n","round 87, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.00014942391779624946\n","round 87, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.00010896807157223519\n","round 87, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 0.00011865511031114044\n","round 87, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.0001596660352822924\n","round 87, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.00010250266962396347\n","round 87, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.00021371938613709874\n","calc smape: 49.51584224326599%\n","MAE: 56.61654205308643\n","RMSE: 184.24887221364696\n","Average Loss:  0.00393547981704421\n","\n","starting avg round 88\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 88, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.006622113362287303\n","round 88, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.003903678422960054\n","round 88, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.0033027686045638146\n","round 88, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.006634948459187792\n","round 88, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.004096711740463174\n","round 88, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.0018986992425717674\n","round 88, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.008587867512168099\n","round 88, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.0004999087315289738\n","round 88, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.008991611032148027\n","round 88, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.004673017467471902\n","round 88, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 5.603705984950383e-05\n","round 88, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.00044385620016588025\n","round 88, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.652404385296905e-05\n","round 88, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.82651284712951e-05\n","round 88, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.00011557884059769731\n","round 88, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.0001157261491146398\n","round 88, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 7.739294414932374e-05\n","round 88, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.0003176664675307124\n","round 88, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.509747980830848e-05\n","round 88, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.00010878216776940723\n","round 88, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 8.660799582165573e-05\n","round 88, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 7.675901103373853e-05\n","round 88, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.0003692749882507737\n","round 88, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.00012795089810424543\n","round 88, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 6.986878680744925e-05\n","round 88, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.0005049952448773963\n","round 88, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.363136979611487e-05\n","round 88, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.00039108514751465663\n","round 88, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.00012254704669041011\n","round 88, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.00042285389463359014\n","round 88, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 9.350209773271798e-05\n","round 88, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.0003747947747407514\n","round 88, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 5.8680694836864065e-05\n","round 88, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.00037559033626166643\n","round 88, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.00015625455215838101\n","round 88, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.00011450319876920343\n","round 88, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 0.00011606348216933577\n","round 88, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.00015796305600781363\n","round 88, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.0001036583587813732\n","round 88, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.0002153353440277257\n","calc smape: 49.42882785871718%\n","MAE: 56.61210269846902\n","RMSE: 184.3330463852033\n","Average Loss:  0.0038375743709106\n","\n","starting avg round 89\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 89, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.00656012969557196\n","round 89, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.003933824436639303\n","round 89, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.003302612932332392\n","round 89, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.006621446759839143\n","round 89, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.00408904775395058\n","round 89, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.0018897238436953304\n","round 89, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.008582371902385994\n","round 89, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.00043101200065263716\n","round 89, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.008951412871413465\n","round 89, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.004645634176475661\n","round 89, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 5.752082318146925e-05\n","round 89, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.0004251622431183933\n","round 89, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.6479245388094827e-05\n","round 89, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.735712802059425e-05\n","round 89, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.0001202566921889498\n","round 89, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.00012857632541697837\n","round 89, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 7.706790240393143e-05\n","round 89, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.0003104185385547515\n","round 89, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.627601860172164e-05\n","round 89, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.00012189961801465996\n","round 89, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 8.065122117224225e-05\n","round 89, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 8.009557114457326e-05\n","round 89, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.00037251155143686835\n","round 89, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.0001248391633583066\n","round 89, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 6.854672290452463e-05\n","round 89, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.0005157976634758859\n","round 89, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.306893374130597e-05\n","round 89, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.00040503000673197675\n","round 89, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.00012711298567020485\n","round 89, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.00040670344112316194\n","round 89, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 9.139022651132629e-05\n","round 89, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.0003736602635139466\n","round 89, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 5.867316856113446e-05\n","round 89, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.00037229010766688057\n","round 89, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.00014701056273582126\n","round 89, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.0001000767935498256\n","round 89, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 0.00010756031147301264\n","round 89, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.00015817243505601784\n","round 89, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.0001024647347936412\n","round 89, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.00021821450332026868\n","calc smape: 49.50386031693676%\n","MAE: 56.431441115068786\n","RMSE: 184.01717836768245\n","Average Loss:  0.00402875754878724\n","\n","starting avg round 90\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 90, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.006637741171289236\n","round 90, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.003905085663843367\n","round 90, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.0033458483189211367\n","round 90, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.0065826396042081925\n","round 90, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.004132633621338756\n","round 90, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.0019099877931044568\n","round 90, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.008594479827609443\n","round 90, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.0004608237678829547\n","round 90, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.00897084020211228\n","round 90, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.004693950738458497\n","round 90, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 5.859708338985827e-05\n","round 90, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.0004321233357456679\n","round 90, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.6261821860785587e-05\n","round 90, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.810094103076284e-05\n","round 90, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.00012819629323614749\n","round 90, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.00012237091090534183\n","round 90, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 7.608403838535845e-05\n","round 90, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.00031580828898437516\n","round 90, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.445286921813281e-05\n","round 90, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.00011975071457267662\n","round 90, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 9.757498531420036e-05\n","round 90, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 7.851251371407255e-05\n","round 90, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.0003673586059968719\n","round 90, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.00012374970620904996\n","round 90, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 6.9613610812829e-05\n","round 90, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.0005636912275284496\n","round 90, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.415635730101192e-05\n","round 90, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.00037609353707271766\n","round 90, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.00012240497530261303\n","round 90, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.00042603579147128457\n","round 90, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 9.203458781874882e-05\n","round 90, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.00036023364789018926\n","round 90, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 5.759267797397374e-05\n","round 90, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.00037819996500080134\n","round 90, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.00015377095209195043\n","round 90, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.00011313873691116378\n","round 90, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 0.00010377735637640788\n","round 90, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.00015852823097925724\n","round 90, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.00010675743332016013\n","round 90, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.00022925265761841726\n","calc smape: 49.458527365934195%\n","MAE: 56.705590051077294\n","RMSE: 184.3802371586476\n","Average Loss:  0.003936534723131237\n","\n","starting avg round 91\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 91, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.0065913217508101\n","round 91, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.003902638559728595\n","round 91, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.0033517263197739206\n","round 91, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.006607629275614662\n","round 91, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.004035661121763822\n","round 91, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.00189364878419188\n","round 91, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.00860096011976046\n","round 91, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.0004318866157128856\n","round 91, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.00893579317822254\n","round 91, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.00464561367490595\n","round 91, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 5.627628492716626e-05\n","round 91, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.0004462295465990403\n","round 91, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.5851502002441134e-05\n","round 91, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.78325890321087e-05\n","round 91, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.00013053725415880356\n","round 91, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.00011664307382375226\n","round 91, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 7.660506347357503e-05\n","round 91, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.0003097799022477623\n","round 91, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 0.0001034862226236198\n","round 91, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.00011114751548900262\n","round 91, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 8.405039961546988e-05\n","round 91, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 7.590979365349166e-05\n","round 91, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.00036409980150762877\n","round 91, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.0001264688793136364\n","round 91, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 7.024154297953698e-05\n","round 91, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.0004966205028072831\n","round 91, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.362412596721307e-05\n","round 91, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.0003941684855297874\n","round 91, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.0001245104468320538\n","round 91, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.00039800342853725713\n","round 91, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 9.472818685805705e-05\n","round 91, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.0003698859888702699\n","round 91, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 5.7530985990134855e-05\n","round 91, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.0003781117824733622\n","round 91, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.00015128565745823965\n","round 91, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.00010969708663261761\n","round 91, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 0.00010580106161179563\n","round 91, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.00015727388891152583\n","round 91, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.0001044732588761016\n","round 91, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.00022566085773952955\n","calc smape: 49.28553839058455%\n","MAE: 55.614436631046985\n","RMSE: 183.46975373768674\n","Average Loss:  0.0038722715749659733\n","\n","starting avg round 92\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 92, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.006570834807852018\n","round 92, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.003885930295967098\n","round 92, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.0033045951110709988\n","round 92, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.0065586080807926396\n","round 92, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.004064267746538722\n","round 92, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.001891683785028623\n","round 92, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.008590552423681529\n","round 92, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.00041098263903092757\n","round 92, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.00894763063739187\n","round 92, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.004665117561151939\n","round 92, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 5.576745528825002e-05\n","round 92, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.00044606829552711633\n","round 92, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.562971117495961e-05\n","round 92, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.7944987749236e-05\n","round 92, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.0001077612273968919\n","round 92, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.00011909857935929072\n","round 92, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 7.549361836416729e-05\n","round 92, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.0003151924499599608\n","round 92, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 0.00010000404142829208\n","round 92, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.00010669076017880536\n","round 92, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 7.745518361243089e-05\n","round 92, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 7.943372357575835e-05\n","round 92, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.0003644061221815978\n","round 92, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.0001221028777211229\n","round 92, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 6.933746703095623e-05\n","round 92, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.0005150640886962979\n","round 92, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.403086143385344e-05\n","round 92, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.0003576632942505446\n","round 92, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.00012593729024956699\n","round 92, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.00040763311621308914\n","round 92, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 9.346023356166761e-05\n","round 92, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.00036962460762879356\n","round 92, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 5.645967236692481e-05\n","round 92, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.0003784887303481811\n","round 92, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.0001456888785306936\n","round 92, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.00010303276738860797\n","round 92, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 9.719457640195675e-05\n","round 92, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.00015796954843574223\n","round 92, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.00010120976809570561\n","round 92, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.0002129887007042809\n","calc smape: 49.612937508926954%\n","MAE: 58.174357301691245\n","RMSE: 185.49260005827568\n","Average Loss:  0.0038080601178964455\n","\n","starting avg round 93\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 93, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.0066130877073322025\n","round 93, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.00388357151366238\n","round 93, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.003299102690237175\n","round 93, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.006560813909995237\n","round 93, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.00406025128073192\n","round 93, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.001897633427038922\n","round 93, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.008573046411454144\n","round 93, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.00043441893532352496\n","round 93, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.008957552989678723\n","round 93, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.004645602669500345\n","round 93, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 5.687698636723904e-05\n","round 93, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.00041948112162312344\n","round 93, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.594264390383224e-05\n","round 93, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.711069716671253e-05\n","round 93, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.00012087585534354058\n","round 93, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.0001192512151695675\n","round 93, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 7.601178416345126e-05\n","round 93, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.00032533315969968417\n","round 93, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.313465933960937e-05\n","round 93, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.00010294377409536533\n","round 93, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 8.246439115363763e-05\n","round 93, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 7.727547575665415e-05\n","round 93, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.0003503490219632762\n","round 93, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.00012717943484728621\n","round 93, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 7.620067732716505e-05\n","round 93, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.000493120725098249\n","round 93, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.429737110482035e-05\n","round 93, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.00036240578499148663\n","round 93, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.00012708392666484415\n","round 93, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.0004393127739084387\n","round 93, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 8.878222534544222e-05\n","round 93, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.00036314472916793814\n","round 93, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 5.620661262030679e-05\n","round 93, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.000373132197117749\n","round 93, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.00014753332294503707\n","round 93, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.00010097468836128036\n","round 93, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 0.00011802235930450217\n","round 93, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.00015883018563126478\n","round 93, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.00010387823068345755\n","round 93, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.00022123508824734015\n","calc smape: 49.44633699954148%\n","MAE: 56.73184048994674\n","RMSE: 184.2693372293633\n","Average Loss:  0.00383163161233858\n","\n","starting avg round 94\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 94, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.00656009605985933\n","round 94, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.0038760721217840906\n","round 94, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.0032812625203015545\n","round 94, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.006563618912228516\n","round 94, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.004026474560045503\n","round 94, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.0018850657444480542\n","round 94, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.008578460630295532\n","round 94, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.0004218002280010427\n","round 94, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.008951290843210053\n","round 94, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.004621039818240597\n","round 94, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 5.6392104616778936e-05\n","round 94, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.0004294943191780476\n","round 94, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.57183982364638e-05\n","round 94, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.714840704206185e-05\n","round 94, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.00011891723096579408\n","round 94, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.00011686709277520483\n","round 94, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 7.613265509982222e-05\n","round 94, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.00032085226254656093\n","round 94, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.358228250481e-05\n","round 94, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.00010178465932345457\n","round 94, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 8.335796152891814e-05\n","round 94, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 7.774418850203801e-05\n","round 94, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.0003541358395783131\n","round 94, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.00012838933818264714\n","round 94, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 7.035982501487783e-05\n","round 94, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.0005333265895127882\n","round 94, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.319056613181471e-05\n","round 94, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.0003557087017855206\n","round 94, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.00012480818850235664\n","round 94, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.0004018584404548164\n","round 94, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 9.002825748081836e-05\n","round 94, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.0003583905342696068\n","round 94, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 5.9446507512867757e-05\n","round 94, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.00037606477573197996\n","round 94, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.00014745486728478293\n","round 94, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.00010703152117587577\n","round 94, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 0.00010767780351475914\n","round 94, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.00015740714091081376\n","round 94, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.00010221075076852114\n","round 94, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.00021406066086995083\n","calc smape: 49.44471383274286%\n","MAE: 57.06575799302788\n","RMSE: 184.635099555471\n","Average Loss:  0.003771145080334557\n","\n","starting avg round 95\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 95, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.0065312416076527095\n","round 95, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.003924675156927801\n","round 95, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.0032798188663686486\n","round 95, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.0065455866528541925\n","round 95, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.004035248017836629\n","round 95, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.001892348073722263\n","round 95, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.008551853800392042\n","round 95, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.00041215892425887953\n","round 95, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.008934437995776532\n","round 95, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.004621564223530836\n","round 95, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 5.495743194346274e-05\n","round 95, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.00042533962446863636\n","round 95, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.6463134903465927e-05\n","round 95, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.729724632099533e-05\n","round 95, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.0001317327640132741\n","round 95, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.00011395808089430049\n","round 95, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 7.621230403336602e-05\n","round 95, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.0003084994651751251\n","round 95, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.030844874554793e-05\n","round 95, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 9.79398082563421e-05\n","round 95, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 8.209659389584495e-05\n","round 95, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 7.696857112684731e-05\n","round 95, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.0003497602736907928\n","round 95, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.00012849575810897868\n","round 95, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 6.887870790300049e-05\n","round 95, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.00048688255109092485\n","round 95, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.326595284430626e-05\n","round 95, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.0003741742800359913\n","round 95, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.00012015206363815065\n","round 95, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.00039316867202744866\n","round 95, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 9.303702086072009e-05\n","round 95, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.0003525521520454537\n","round 95, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 5.976300940346845e-05\n","round 95, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.0003741725998094937\n","round 95, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.00015731649824601845\n","round 95, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 0.00010929376484065352\n","round 95, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 9.437132517372708e-05\n","round 95, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.0001576480129634152\n","round 95, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.00010339957339056126\n","round 95, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.0002141643135052652\n","calc smape: 49.06715228571877%\n","MAE: 55.165665192229774\n","RMSE: 183.29783339231005\n","Average Loss:  0.003685778002156309\n","\n","starting avg round 96\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 96, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.006542069055805251\n","round 96, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.0038799198269511433\n","round 96, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.003265856723633729\n","round 96, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.006541874276341074\n","round 96, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.004008078590101961\n","round 96, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.001878801616840064\n","round 96, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.008572623807205157\n","round 96, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.00037663402586726345\n","round 96, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.008909738040529186\n","round 96, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.004602294781112246\n","round 96, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 5.549579847700608e-05\n","round 96, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.000392940804886166\n","round 96, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.581027677984041e-05\n","round 96, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.626012026256438e-05\n","round 96, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.00011387425668005932\n","round 96, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.0001130632879145261\n","round 96, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 7.536237639474816e-05\n","round 96, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.0003219429379028456\n","round 96, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.985071169791939e-05\n","round 96, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 9.615709138545623e-05\n","round 96, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 7.831691787682107e-05\n","round 96, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 7.67923936398967e-05\n","round 96, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.0003605309510541182\n","round 96, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.0001295331053207909\n","round 96, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 7.080142447486131e-05\n","round 96, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.000471360348196218\n","round 96, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.277520126575708e-05\n","round 96, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.00033513864114606155\n","round 96, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.00012327439864228442\n","round 96, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.00037508698057666024\n","round 96, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 9.273267979941532e-05\n","round 96, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.00036208137057006497\n","round 96, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 5.680492081491398e-05\n","round 96, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.000377632989381839\n","round 96, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.00015143108206367676\n","round 96, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 9.613543543959427e-05\n","round 96, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 0.00010371442481625438\n","round 96, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.0001588347718569701\n","round 96, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 9.884034641008502e-05\n","round 96, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.00021391891623857696\n","calc smape: 49.241492216990366%\n","MAE: 55.921246640974445\n","RMSE: 183.6402813559062\n","Average Loss:  0.003772554887971513\n","\n","starting avg round 97\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 97, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.006553712525471512\n","round 97, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.0038569095860501485\n","round 97, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.0032779037095938945\n","round 97, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.00653257008109774\n","round 97, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.004011905440295648\n","round 97, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.0018829774760108977\n","round 97, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.008591962437744119\n","round 97, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.0004096961081034221\n","round 97, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.008894792200797903\n","round 97, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.004633978953019583\n","round 97, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 5.445633594469903e-05\n","round 97, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.0003956837195541343\n","round 97, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.587558223079213e-05\n","round 97, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.575231360793364e-05\n","round 97, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.00011560530723879005\n","round 97, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.00012051612395274397\n","round 97, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 7.586884755385525e-05\n","round 97, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.00030702314549092667\n","round 97, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.763927945576661e-05\n","round 97, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.00011808102310949054\n","round 97, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 8.09974717940674e-05\n","round 97, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 7.727993549286277e-05\n","round 97, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.00035341318393225914\n","round 97, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.00012539574246212784\n","round 97, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 7.596768153916857e-05\n","round 97, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.00047391486389512604\n","round 97, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.288425229935715e-05\n","round 97, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.00035555467210152906\n","round 97, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.0001201866260609157\n","round 97, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.0003777045037298064\n","round 97, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 9.340758547945631e-05\n","round 97, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.00034748902362480294\n","round 97, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 5.8226031780707536e-05\n","round 97, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.0003688818958055759\n","round 97, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.00015712022123385135\n","round 97, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 9.591187634734006e-05\n","round 97, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 0.00010217654309891651\n","round 97, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.0001582951725715316\n","round 97, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.00010231394245844662\n","round 97, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.00022120795473609981\n","calc smape: 49.28054615567482%\n","MAE: 56.129999409773546\n","RMSE: 183.8394100087315\n","Average Loss:  0.0037704823357536713\n","\n","starting avg round 98\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 98, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.006580521369219892\n","round 98, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.0038976935861033523\n","round 98, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.0032683470344636594\n","round 98, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.006537393026519567\n","round 98, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.003981923809208508\n","round 98, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.0018928890848266232\n","round 98, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.008524593315087259\n","round 98, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.00040533179422449643\n","round 98, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.008909666278798667\n","round 98, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.004670587305944145\n","round 98, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 5.516058255042564e-05\n","round 98, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.0004032743649336875\n","round 98, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.522777489260729e-05\n","round 98, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.676437592505993e-05\n","round 98, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.0001126564897344064\n","round 98, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.00011381166597500073\n","round 98, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 7.559637362776683e-05\n","round 98, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.00030458429076712825\n","round 98, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.318603305733371e-05\n","round 98, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 0.00010818342775564815\n","round 98, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 7.924707995243807e-05\n","round 98, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 7.768991337632707e-05\n","round 98, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.00035273309263824824\n","round 98, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.00012524183419567893\n","round 98, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 7.077203444591111e-05\n","round 98, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.00047786078513516796\n","round 98, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.196597290600688e-05\n","round 98, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.0003492892353408803\n","round 98, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.00012217540357336733\n","round 98, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.00040351421557716083\n","round 98, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 8.997510466152953e-05\n","round 98, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.0003643845253204095\n","round 98, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 5.602741399814347e-05\n","round 98, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.0003713983044560467\n","round 98, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.00014540815076153585\n","round 98, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 9.644609901572821e-05\n","round 98, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 0.00011223795370694593\n","round 98, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.0001575433745125887\n","round 98, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 0.00010173420637497825\n","round 98, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.0002153990705109108\n","calc smape: 49.35035311210715%\n","MAE: 56.57534800340743\n","RMSE: 184.03010078053\n","Average Loss:  0.0036546790315131134\n","\n","starting avg round 99\n","clients:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n","round 99, starting client 1/40, id: 0\n","Epoch [1/1], Train Loss: 0.0065748757915571315\n","round 99, starting client 2/40, id: 1\n","Epoch [1/1], Train Loss: 0.0038776627251146632\n","round 99, starting client 3/40, id: 2\n","Epoch [1/1], Train Loss: 0.0032504778646398336\n","round 99, starting client 4/40, id: 3\n","Epoch [1/1], Train Loss: 0.006507419939485511\n","round 99, starting client 5/40, id: 4\n","Epoch [1/1], Train Loss: 0.00396581817351814\n","round 99, starting client 6/40, id: 5\n","Epoch [1/1], Train Loss: 0.0018564517771924977\n","round 99, starting client 7/40, id: 6\n","Epoch [1/1], Train Loss: 0.008539005432144876\n","round 99, starting client 8/40, id: 7\n","Epoch [1/1], Train Loss: 0.0003949365549747849\n","round 99, starting client 9/40, id: 8\n","Epoch [1/1], Train Loss: 0.008867606138145284\n","round 99, starting client 10/40, id: 9\n","Epoch [1/1], Train Loss: 0.004564858316111246\n","round 99, starting client 11/40, id: 10\n","Epoch [1/1], Train Loss: 5.826606942801763e-05\n","round 99, starting client 12/40, id: 11\n","Epoch [1/1], Train Loss: 0.00038751735961081344\n","round 99, starting client 13/40, id: 12\n","Epoch [1/1], Train Loss: 4.608606190004139e-05\n","round 99, starting client 14/40, id: 13\n","Epoch [1/1], Train Loss: 7.635101258074428e-05\n","round 99, starting client 15/40, id: 14\n","Epoch [1/1], Train Loss: 0.000111655759050572\n","round 99, starting client 16/40, id: 15\n","Epoch [1/1], Train Loss: 0.00011516458073401738\n","round 99, starting client 17/40, id: 16\n","Epoch [1/1], Train Loss: 7.676423115299257e-05\n","round 99, starting client 18/40, id: 17\n","Epoch [1/1], Train Loss: 0.0003201239387759746\n","round 99, starting client 19/40, id: 18\n","Epoch [1/1], Train Loss: 9.331659274331676e-05\n","round 99, starting client 20/40, id: 19\n","Epoch [1/1], Train Loss: 9.65012382364096e-05\n","round 99, starting client 21/40, id: 20\n","Epoch [1/1], Train Loss: 8.11279644251174e-05\n","round 99, starting client 22/40, id: 21\n","Epoch [1/1], Train Loss: 7.543558029035259e-05\n","round 99, starting client 23/40, id: 22\n","Epoch [1/1], Train Loss: 0.000352796143098593\n","round 99, starting client 24/40, id: 23\n","Epoch [1/1], Train Loss: 0.00012638349265411565\n","round 99, starting client 25/40, id: 24\n","Epoch [1/1], Train Loss: 7.133621444462994e-05\n","round 99, starting client 26/40, id: 25\n","Epoch [1/1], Train Loss: 0.00047254120987158147\n","round 99, starting client 27/40, id: 26\n","Epoch [1/1], Train Loss: 6.333593198957845e-05\n","round 99, starting client 28/40, id: 27\n","Epoch [1/1], Train Loss: 0.0003439712069978538\n","round 99, starting client 29/40, id: 28\n","Epoch [1/1], Train Loss: 0.00012282257258838008\n","round 99, starting client 30/40, id: 29\n","Epoch [1/1], Train Loss: 0.00037700948191091545\n","round 99, starting client 31/40, id: 30\n","Epoch [1/1], Train Loss: 9.856357788911347e-05\n","round 99, starting client 32/40, id: 31\n","Epoch [1/1], Train Loss: 0.000350180252748292\n","round 99, starting client 33/40, id: 32\n","Epoch [1/1], Train Loss: 5.515760714810572e-05\n","round 99, starting client 34/40, id: 33\n","Epoch [1/1], Train Loss: 0.0003598820289231039\n","round 99, starting client 35/40, id: 34\n","Epoch [1/1], Train Loss: 0.0001435251609385497\n","round 99, starting client 36/40, id: 35\n","Epoch [1/1], Train Loss: 9.905506885843351e-05\n","round 99, starting client 37/40, id: 36\n","Epoch [1/1], Train Loss: 9.70795005222109e-05\n","round 99, starting client 38/40, id: 37\n","Epoch [1/1], Train Loss: 0.00015498215081160598\n","round 99, starting client 39/40, id: 38\n","Epoch [1/1], Train Loss: 9.972278008650324e-05\n","round 99, starting client 40/40, id: 39\n","Epoch [1/1], Train Loss: 0.00021561989170651132\n","calc smape: 49.265151524362125%\n","MAE: 55.87651101731541\n","RMSE: 183.55278407607275\n","Average Loss:  0.0037304460680201526\n","CPU times: user 4h 22min 56s, sys: 2min 18s, total: 4h 25min 14s\n","Wall time: 4h 24min 54s\n"]}],"source":["%%time\n","lstm_K5_avg = copy.deepcopy(lstm)\n","outputs_avg, targets_avg, loss_avg, smape_avg, mae_avg, rmse_avg = fedavg(\n","    global_model = lstm_K5_avg,\n","    client_train_loader = train_loader,\n","    test_loader = test_loader,\n","    label_sc = label_scalers,\n","    n_clients = n_clients,\n","    num_clients_per_round = num_clients_per_round,\n","    batch_size = batch_size,\n","    num_local_epochs = num_local_epochs,\n","    lr = lr,\n","    max_rounds = max_rounds,\n","    model_type = model_type,\n","    device = device,\n",")"]},{"cell_type":"code","source":["np.save(f'metrics/fedavg_lstm_outputs_C{num_clients_per_round}-n5.npy', np.array(outputs_avg, dtype=object))\n","np.save(f'metrics/fedavg_lstm_targets_C{num_clients_per_round}-n5.npy', np.array(targets_avg, dtype=object))\n","np.save(f'metrics/fedavg_lstm_loss_C{num_clients_per_round}-n5.npy', loss_avg)\n","np.save(f'metrics/fedavg_lstm_smape_C{num_clients_per_round}-n5.npy', smape_avg)\n","np.save(f'metrics/fedavg_lstm_mae_C{num_clients_per_round}-n5.npy', mae_avg)\n","np.save(f'metrics/fedavg_lstm_rmse_C{num_clients_per_round}-n5.npy', rmse_avg)"],"metadata":{"id":"Is91ckJBZs3b","executionInfo":{"status":"ok","timestamp":1713190374869,"user_tz":-120,"elapsed":723,"user":{"displayName":"ff ff","userId":"03856258937076952853"}}},"id":"Is91ckJBZs3b","execution_count":14,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"fXZMebwQFprS"},"id":"fXZMebwQFprS","execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"V100","machine_shape":"hm"},"kernelspec":{"display_name":"fed","language":"python","name":"fed"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":5}